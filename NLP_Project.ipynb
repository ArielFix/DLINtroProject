{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArielFix/DLINtroProject/blob/ImportRobertaPreTrained/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "gXXJiRFgYhKz",
        "outputId": "c0e7f70e-9caa-433e-e11b-cceec1747099"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-296801345cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbranch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"git\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rev-parse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--abbrev-ref\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<a href=\"https://colab.research.google.com/github/ArielFix/DLINtroProject/blob/{branch}/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[1;32m    416\u001b[0m                **kwargs).stdout\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    517\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['git', 'rev-parse', '--abbrev-ref', 'HEAD']' returned non-zero exit status 128."
          ]
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "import subprocess\n",
        "\n",
        "branch = subprocess.check_output([\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"]).decode()[:-1]\n",
        "HTML('<a href=\"https://colab.research.google.com/github/ArielFix/DLINtroProject/blob/{branch}/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'.format(branch=branch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpMqyzzkYhLB"
      },
      "source": [
        "## Notes:\n",
        "* Running may require commands in the bottom of the notebook first\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "peWUcuINV7sS"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "\n",
        "# use GPU for computation if possible: Go to RUNTIME -> CHANGE RUNTIME TYPE -> GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "804WKMCAWEe7",
        "outputId": "d7260ba3-6495-4eee-ab4b-59816a26bfd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "train_path = '/content/gdrive/MyDrive/NLP_Project/data/train.csv'\n",
        "test_path = '/content/gdrive/My Drive/NLP_Project/data/test.csv'\n",
        "sample_submission_path = '/content/gdrive/MyDrive/NLP_Project/data/sample_submission.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yAnJ7d3vYqsV"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "#print(train_df.to_string())\n",
        "#print(test_df.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0syMlj9ae_E"
      },
      "source": [
        "**A quick look at our data**\n",
        "Let's look at our data... first, some examples of what is NOT a disaster tweet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byonChzkajoQ",
        "outputId": "19209acd-a2f1-4e60-e2fd-f2e14a898567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What's up man?\n",
            "I love fruits\n",
            "Summer is lovely\n",
            "My car is so fast\n",
            "What a goooooooaaaaaal!!!!!!\n"
          ]
        }
      ],
      "source": [
        "print('\\n' .join(map(str, train_df[train_df[\"target\"] == 0][\"text\"].values[0:5])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM_OM_EScYgJ"
      },
      "source": [
        "And some examples of what is a disaster tweet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_DdvOhrcc8s",
        "outputId": "0ff92969-c5e3-443a-b791-2e580d557e20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
            "Forest fire near La Ronge Sask. Canada\n",
            "All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
            "13,000 people receive #wildfires evacuation orders in California \n",
            "Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n"
          ]
        }
      ],
      "source": [
        "print('\\n' .join(map(str, train_df[train_df[\"target\"] == 1][\"text\"].values[0:5])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5_Jex7SdJdU"
      },
      "source": [
        "The words contained in each tweet are a good indicator of whether they're about a real disaster or not. This is not entirely correct, but it's a great place to start.\n",
        "\n",
        "We'll use scikit-learn's `CountVectorizer` to count the words in each tweet and turn them into data our machine learning model can process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLFGPgObdhfi",
        "outputId": "a676c428-0267-43b5-ff0a-8ac76613cf91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first 5 tweets in the data: \n",
            "\n",
            "[FORBES]: China's Stock Market Crash: Are There Gems In The Rubble?: ChinaÛªs stock market crash this summer ha... http://t.co/Q4grDpAjr5\n",
            "Former Township fire truck being used in Philippines - Langley Times http://t.co/L90dCPV9Zu #Philippines\n",
            "@EnvySeven My beautiful Aquarius queenmy Siren of the cliffs and pretenses of overtures.Please sing this phantom songfor you alone shall\n",
            "FAAN orders evacuation of abandoned aircraft at MMA: FAAN noted that the action had become neces... http://t.co/tlS40nqiPN Via @todayngr\n",
            "Who is bringing the tornadoes and floods. Who is bringing the climate change. God is after America He is plaguing her\n",
            " \n",
            "#FARRAKHAN #QUOTE\n",
            "\n",
            "\n",
            "(1, 77)\n",
            "[[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 1 2 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1\n",
            "  0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 2 1 0 1 1 1 0 0 0 0 0 0\n",
            "  0 0 0 0 1]]\n"
          ]
        }
      ],
      "source": [
        "train_df, val_df = model_selection.train_test_split(train_df)\n",
        "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
        "\n",
        "## let's get counts for the first 5 tweets in the data\n",
        "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])\n",
        "print('The first 5 tweets in the data: \\n')\n",
        "print('\\n' .join(map(str, train_df[\"text\"][0:5])))\n",
        "print('\\n')\n",
        "## we use .todense() here because these vectors are \"sparse\" (only non-zero elements are kept to save space)\n",
        "print(example_train_vectors[0].todense().shape)\n",
        "print(example_train_vectors[0].todense())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usIeYe9Qe-jg"
      },
      "source": [
        "**The above tells us that:**\n",
        "\n",
        "1.   There are 54 unique words (or \"tokens\") in the first five tweets.\n",
        "2.   The first tweet contains only some of those unique tokens - all of the non-zero counts above are the tokens that DO exist in the first tweet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcA5TFkdfjHZ"
      },
      "source": [
        "Now let's create vectors for all of our tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OtIFyab_fit-"
      },
      "outputs": [],
      "source": [
        "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
        "\n",
        "## note that we're NOT using .fit_transform() on test_df. Using just .transform() makes sure\n",
        "# that the tokens in the train vectors are the only ones mapped to the test vectors - \n",
        "# i.e. that the train and test vectors use the same set of tokens.\n",
        "val_vectors = count_vectorizer.transform(val_df[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpPhYkkGf_jl"
      },
      "source": [
        "**Our model**\n",
        "\n",
        "As we mentioned above, we think the words contained in each tweet are a good indicator of whether they're about a real disaster or not. The presence of particular word (or set of words) in a tweet might link directly to whether or not that tweet is real.\n",
        "\n",
        "What we're assuming here is a linear connection. So let's build a linear model and see!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VRwkRi7hgBaA"
      },
      "outputs": [],
      "source": [
        "## Our vectors are really big, so we want to push our model's weights\n",
        "## toward 0 without completely discounting different words - ridge regression \n",
        "## is a good way to do this.\n",
        "clf = linear_model.RidgeClassifier()\n",
        "clf.fit(train_vectors, train_df[\"target\"]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqW_HlFzLYUd",
        "outputId": "609f9890-eec8-452e-9d4a-0ed2f03e350e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7424144609425437"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "val_target = clf.predict(val_vectors)\n",
        "f1_score(y_pred=val_target, y_true=val_df[\"target\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erAJlNvqKglh"
      },
      "source": [
        "Let's test our model and see how well it does on the training data. For this we'll use cross-validation - where we train on a portion of the known data, then validate it with the rest. If we do this several times (with different portions) we can get a good idea for how a particular model or method performs.\n",
        "\n",
        "The metric for this competition is F1, so let's use that here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug_ecfZuKxxE",
        "outputId": "8bf4820b-d6da-41ee-9380-b779a7b95f04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.72796449, 0.73186959, 0.73337637])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "3522czRaPt5B"
      },
      "outputs": [],
      "source": [
        "results = pd.read_csv(sample_submission_path)\n",
        "results.target = clf.predict(count_vectorizer.transform(test_df[\"text\"]))\n",
        "results.to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFJs2yb-PqnQ"
      },
      "source": [
        "![ridge_score.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I42bT7YlK1Q1"
      },
      "source": [
        "The above scores aren't terrible! It looks like our assumption will score roughly 0.65 on the leaderboard. There are lots of ways to potentially improve on this (TFIDF, LSA, LSTM / RNNs, the list is long!) - we will give any of them a shot!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcux5Ux2PP9y"
      },
      "source": [
        "\n",
        "Here's how we could use an RNN to solve the disaster tweets problem:\n",
        "\n",
        "\n",
        "1.   Preprocess the tweet data by tokenizing the text and creating a vocabulary. we \n",
        "may also want to consider applying techniques such as stemming and lemmatization to help reduce the dimensionality of the data.\n",
        "3. Pad the sequences of integers to ensure that all of the tweets have the same length.\n",
        "4. Build an RNN model with an embedding layer, followed by one or more LSTM or GRU layers, and ending with a dense layer for classification.\n",
        "5. Train the model on the disaster tweets data, using binary cross-entropy loss and an optimizer such as Adam.\n",
        "6. Evaluate the model's performance on a held-out test set and fine-tune the model as needed to improve its accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_4anoqqQXpN"
      },
      "source": [
        "We'll may also try and fine-tune: [twitter-roberta-sentiment](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment) for our purposes. If possible within the given schedule and resources. We will also see if we the results from the pre-trained model improve our model performance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11xfcYs0ajbk",
        "outputId": "d3547679-fe97-4051-a5e0-7d469b409531"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import csv\n",
        "import urllib.request\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "OpBN3F1-agUI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imperting pre-trained roberta:\n",
        "task='sentiment'\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "roberta_model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "roberta_model.save_pretrained(MODEL)\n",
        "\n",
        "def preprocess(text):\n",
        "    new_text = []\n",
        " \n",
        " \n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "d936815c1b154b5ca8e42aeaf646afab",
            "509a92c90728466ba28e51af8715a79f",
            "c223cf911d7b4a95b100eb69896068a9",
            "ddeb3c46b7dc4d0ebee5239d3ba8b95e",
            "13aec32f6bb9460ab2ab078964982614",
            "fb4e64bf22ba43a7b510ad6e77d6bbd1",
            "c3b0c373b1b7499c84742c227f05eaab",
            "735ef05567674001bf14703f1cb1cbd1",
            "373f19e1a13040f9a2b89bc5d754f519",
            "b620a242471149bc9e6faed566d6b55b",
            "57b30247bd0e4e2f914710bb599a2258",
            "56d3d190bcb14afc9cd865b2e2b5f3e0",
            "1f782d946aed4600a9c935d05fd15d96",
            "30920e6f5cc8468b8f55980d7bb2c4aa",
            "7b396d0201b34af9a00ace9e7cb492e8",
            "ff4c5897b7e349f5baba621a9e4eae47",
            "dc15da8855d54626b21d75bd08552be2",
            "3716b31c4435471989101a31e44d88c9",
            "404e9f2aecd74101b3371ef10881da05",
            "9637221d318b4d148677bba2289c950c",
            "97c4d61b6bbd40d9a9642d31daaab10f",
            "e008e0cf9bad4c21973053cec140900f",
            "cba0d261913e40adbe1253a435f8789b",
            "e86880cc40554eabb6584f514359f5c5",
            "5fa96d7ddbef4847a7fa1303a3ce9e24",
            "6dc8356129164b5eac3637fe56d56993",
            "58e90c2326ae4450a7c6523f56795348",
            "f999100a02f24850bd3abc3c01fe5ee0",
            "cc28870e0fd64cb197a438a1e60e99e8",
            "32363a41fc6242e7b8a95b25e3796e9c",
            "2a813027bb374fe49a5850e314b550d4",
            "98015b7385cf4dd181cc658d749a115f",
            "8b86bf37e1834a8ba8e00b0b7949aa14",
            "157f8e7ef55344388bec096f850b17a3",
            "af71bd6085d9488d82a593291162951e",
            "d130f42a09ad4351aa070860b19393c4",
            "48607fd6f02842e19f4e45297a4be42b",
            "e5ef8223d7ad438f8ed50cb96988abe3",
            "b6839731f0734ed1ac65eff12bda377d",
            "dd93e3cdcb314deabf62b512d8c44546",
            "9cc374899a1f4c258c963b662d67bdd7",
            "957f6b7fa0f64a7fb135261a2663b8f4",
            "4b101244f0c24b65ac46bf9115fadb01",
            "6c03ddee5f3e455fa40e268d954e0686",
            "57b51a430bf24bd7a4b27dec39547938",
            "1362d98e8e7d47aebe3fe34588332594",
            "98f63b305d394735bf528fbde6c9aeee",
            "4b069ff4bf724d3eab8f4271e3e1341c",
            "18d699dd8b814e9e9a77b7703e0b9873",
            "7d60773b54db4ef8b6f7f481be256137",
            "8f1e56f75f4c46bf970ac66bd2c6b3c5",
            "6622edba9e2348bca1a0e13f23cabefe",
            "1f4562f3c0454c44ae88121018fa5f3c",
            "593562ea9685454f98497a795b69705a",
            "e4adc20f63a04807b10bd48554b07d7e"
          ]
        },
        "id": "yhMjkW1fa7v5",
        "outputId": "8770fd6b-0963-4be9-d689-d274a6557118"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d936815c1b154b5ca8e42aeaf646afab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56d3d190bcb14afc9cd865b2e2b5f3e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cba0d261913e40adbe1253a435f8789b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "157f8e7ef55344388bec096f850b17a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57b51a430bf24bd7a4b27dec39547938"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing roberta model architecture\n",
        "roberta_model.modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne8Bz-j_cpaE",
        "outputId": "48b20615-6e49-4eff-b50e-3ccb12543fcd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.modules of RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing roberta model last layer to adjust the output to the required task\n",
        "\n",
        "roberta_model.classifier.out_proj = nn.Sequential(nn.Linear(in_features=768, out_features=1, bias=True), nn.Sigmoid())\n",
        "\n",
        "roberta_model.modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG1SoXnwcYN9",
        "outputId": "1f6750b0-6d16-419e-8566-a63589f72ed1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.modules of RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Sequential(\n",
              "      (0): Linear(in_features=768, out_features=1, bias=True)\n",
              "      (1): Sigmoid()\n",
              "    )\n",
              "  )\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing roberta model parameters - only the classifier can be trained\n",
        "for parameter in roberta_model.parameters():\n",
        "  parameter.requires_grad = False\n",
        "\n",
        "for classifier_parameter in roberta_model.classifier.parameters():\n",
        "  classifier_parameter.requires_grad = True\n",
        "\n",
        "# for parameter in roberta_model.parameters():\n",
        "#   print(parameter.requires_grad)"
      ],
      "metadata": {
        "id": "KQvRopJXghhJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_data = pd.DataFrame()\n",
        "train_text_data[\"text\"] =  train_df['text']\n",
        "train_text_data[\"target\"] = train_df['target']\n",
        "train_text_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "for line in range(0, len(train_text_data['text'])):\n",
        "  train_text_data['text'][line] = preprocess(train_text_data['text'][line])\n",
        "\n",
        "print(\"train text example:\")\n",
        "train_text_data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "IjwCsHVbpeco",
        "outputId": "fe83e5db-3012-47d9-b892-9b43a4029fdd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-0cbc12547971>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_text_data['text'][line] = preprocess(train_text_data['text'][line])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train text example:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target\n",
              "0  [FORBES]: China's Stock Market Crash: Are Ther...       0\n",
              "1  Former Township fire truck being used in Phili...       1\n",
              "2  @user My beautiful Aquarius queenmy Siren of t...       0\n",
              "3  FAAN orders evacuation of abandoned aircraft a...       1\n",
              "4  Who is bringing the tornadoes and floods. Who ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8be77b1b-6bde-4411-b99c-e70a6de687f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[FORBES]: China's Stock Market Crash: Are Ther...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Former Township fire truck being used in Phili...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user My beautiful Aquarius queenmy Siren of t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FAAN orders evacuation of abandoned aircraft a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who is bringing the tornadoes and floods. Who ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8be77b1b-6bde-4411-b99c-e70a6de687f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8be77b1b-6bde-4411-b99c-e70a6de687f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8be77b1b-6bde-4411-b99c-e70a6de687f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"val text example:\")\n",
        "val_text_data = pd.DataFrame()\n",
        "val_text_data[\"text\"], val_text_data[\"target\"] = val_df[\"text\"], val_df['target']\n",
        "val_text_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "for line in range(0, len(val_text_data['text'])):\n",
        "  val_text_data['text'][line] = preprocess(val_text_data['text'][line])\n",
        "\n",
        "val_text_data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "-8zMzBIT96mh",
        "outputId": "58349b56-e8e2-4bc8-8e29-5ab4de2caa70"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val text example:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-a3275e05f40e>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_text_data['text'][line] = preprocess(val_text_data['text'][line])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target\n",
              "0  3 Years After the Sikh Temple Massacre Hate-Vi...       1\n",
              "1  Pendleton media office said only fire on base ...       1\n",
              "2  IT STARTS A FOREST FIRE THAT CANNOT BE PUT OUT...       1\n",
              "3  James Kunstler: How bad architecture wrecked c...       0\n",
              "4  #science Now that a piece of wreckage from fli...       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a20fa5ce-281c-459e-92b7-161400eb4ada\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3 Years After the Sikh Temple Massacre Hate-Vi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pendleton media office said only fire on base ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IT STARTS A FOREST FIRE THAT CANNOT BE PUT OUT...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>James Kunstler: How bad architecture wrecked c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#science Now that a piece of wreckage from fli...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a20fa5ce-281c-459e-92b7-161400eb4ada')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a20fa5ce-281c-459e-92b7-161400eb4ada button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a20fa5ce-281c-459e-92b7-161400eb4ada');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def estimate_roberta_model_accuracy(model_outputs, labels):\n",
        "  y_preds = torch.zeros(len(model_outputs), dtype=torch.int64)\n",
        "\n",
        "  model_preds = torch.tensor(model_outputs) > 0.5\n",
        "  y_preds[model_preds] = 1\n",
        "  y_preds = pd.Series(y_preds.detach())\n",
        "  \n",
        "  print('y pred est:', y_preds)\n",
        "  print('labels est:', labels)\n",
        "\n",
        "  return f1_score(y_pred=y_preds, y_true=labels)\n",
        "\n",
        "def get_roberta_train_data_accuracy(model, data, batch_size = 1):\n",
        "  model.eval()\n",
        "  model_outputs = []\n",
        "  for i in range(0, len(data), batch_size):\n",
        "    if (i + batch_size) > len(data):\n",
        "      break\n",
        "    data_idx = range(i,i+batch_size)\n",
        "    text_data = data['text'][data.index[data_idx]].to_list()\n",
        "    preprocessed_data = tokenizer(text_data, return_tensors='pt', padding=True).to(device)\n",
        "\n",
        "    model_output = roberta_model.forward(**preprocessed_data).logits\n",
        "    preprocessed_data.to('cpu')\n",
        "    model_outputs.append(model_output.detach().to('cpu'))\n",
        "  model_train_labels = data['target']\n",
        "  return estimate_roberta_model_accuracy(model_outputs, model_train_labels)\n",
        "\n",
        "\n",
        "\n",
        "def train_roberta_model(roberta_model, train_data, val_data, learning_rate=1e-3, weight_decay=0, batch_size=32, num_epoches=30, check_point_path=None):\n",
        "  \n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(roberta_model.parameters(),\n",
        "                          lr=learning_rate,\n",
        "                          weight_decay=weight_decay)\n",
        "\n",
        "  epoches, train_losses, val_losses = [], [], []\n",
        "  train_accs, val_accs  = [], []\n",
        "  \n",
        "  for epoch in range(0,num_epoches):\n",
        "    roberta_model.train()\n",
        "    model_val_outputs = []\n",
        "    epoch_train_loss = 0\n",
        "    train_iterations_counter = 0\n",
        "    \n",
        "\n",
        "    train_random_order = torch.randperm(len(train_data)).numpy()\n",
        "    val_random_order = torch.randperm(len(val_data)).numpy()\n",
        "    for i in range(0, len(train_data), batch_size):\n",
        "      if (i + batch_size) > len(train_data):\n",
        "        break\n",
        "      train_iterations_counter += 1\n",
        "      data_idx = train_random_order[i:i+batch_size]\n",
        "      labels = train_data['target'][train_data.index[data_idx]].to_list()\n",
        "      labels = torch.tensor([labels], dtype=torch.float32).to(device)\n",
        "      data = train_data['text'][train_data.index[data_idx]].to_list()\n",
        "      preprocessed_data = tokenizer(data, return_tensors='pt', padding=True).to(device)\n",
        "      print('labels on train: ', labels, ' labels shape: ', labels.shape)\n",
        "      model_output = roberta_model.forward(**preprocessed_data).logits\n",
        "      print('model_output on train: ', model_output, ' model_output shape: ', model_output.shape, ' model output: ', model_output)\n",
        "      loss = criterion(model_output, labels)                   # compute the total loss\n",
        "      loss.backward()                      # compute updates for each parameter\n",
        "      optimizer.step()                      # make the updates for each parameter\n",
        "      optimizer.zero_grad() \n",
        "      preprocessed_data.to('cpu')\n",
        "      epoch_train_loss += loss.item()/batch_size\n",
        "    train_losses.append(epoch_train_loss/train_iterations_counter)\n",
        "    train_accs.append(get_roberta_train_data_accuracy(roberta_model, train_data, batch_size))\n",
        "\n",
        "    roberta_model.eval()\n",
        "    val_iterations_counter = 0\n",
        "    epoch_val_loss = 0\n",
        "    for i in range(0, len(val_data), batch_size):\n",
        "      if (i + batch_size) > len(val_data):\n",
        "        break\n",
        "      val_iterations_counter += 1\n",
        "      data_idx = range(i,i+batch_size)\n",
        "      labels = val_data['target'][val_data.index[data_idx]].to_list()\n",
        "      labels = torch.tensor([labels], dtype=torch.float32).to(device)\n",
        "      data = val_data['text'][val_data.index[data_idx]].to_list()\n",
        "      preprocessed_data = tokenizer(data, return_tensors='pt', padding=True).to(device)\n",
        "\n",
        "      model_output = roberta_model.forward(**preprocessed_data).logits\n",
        "      loss = criterion(model_output, labels)                   # compute the total loss\n",
        "\n",
        "      preprocessed_data.to('cpu')\n",
        "      labels.to('cpu')\n",
        "      model_val_outputs.append(model_output.detach().to('cpu'))\n",
        "       \n",
        "      # print(model_output.logits.detach().numpy())\n",
        "      epoch_val_loss += loss.item()/batch_size\n",
        "\n",
        "    model_val_labels = val_data['target']\n",
        "    val_losses.append(epoch_val_loss/ val_iterations_counter)\n",
        "    epoches.append(epoch)\n",
        "    val_acc_estimation = estimate_roberta_model_accuracy(model_val_outputs, model_val_labels)\n",
        "    val_accs.append(val_acc_estimation)\n",
        "    print(f\"====> Epoch: {epoch} Average train loss: {train_losses[epoch]:.4f}, train acc: {train_accs[epoch]:.4f}, Average val loss: {val_losses[epoch]:.4f}, val acc: {val_accs[epoch]:.4f}\")\n",
        "  \n",
        "  return epoches, train_losses, val_losses, train_accs, val_accs\n",
        "\n",
        "def plot_learning_curve(epoches, train_losses, val_losses, train_accs, val_accs):\n",
        "    \"\"\"\n",
        "    Plot the learning curve.\n",
        "    \"\"\"\n",
        "    plt.title(\"Learning Curve: Loss per epoch\")\n",
        "    plt.plot(epoches, train_losses, label=\"Train\")\n",
        "    plt.plot(epoches, val_losses, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(['Train', 'Train'])\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Learning Curve: Accuracy per epoch\")\n",
        "    plt.plot(epoches, train_accs, label=\"Train\")\n",
        "    plt.plot(epoches, val_accs, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(['Train', 'Train'])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "kk2y4gZ8rg-f"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "train_data_try = train_text_data[0:10]\n",
        "# train_data =  torch.utils.data.DataLoader(train_text.to_list(), batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "# val_data = torch.utils.data.DataLoader(train_text.to_list(), batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "device = 'cpu'\n",
        "roberta_model.to(device)\n",
        "train_roberta_model(roberta_model, train_data_try, train_data_try, learning_rate=1e-3, weight_decay=0, batch_size=1, num_epoches=5, check_point_path=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdfhLYFs3Ms-",
        "outputId": "98377c74-f31a-4e68-f7cc-ddc3a3143f04"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.4727]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.4727]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.0857]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.0857]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.0829]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.0829]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.5285]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.5285]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.8827]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.8827]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.8826]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.8826]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.9488]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.9488]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.9971]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.9971]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.9730]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.9730]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.8551]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.8551]], grad_fn=<SigmoidBackward0>)\n",
            "y pred est: 0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "5    1\n",
            "6    1\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "dtype: int64\n",
            "labels est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "Name: target, dtype: int64\n",
            "y pred est: 0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "5    1\n",
            "6    1\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "dtype: int64\n",
            "labels est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "Name: target, dtype: int64\n",
            "====> Epoch: 0 Average train loss: 1.7240, train acc: 0.7500, Average val loss: 1.1447, val acc: 0.7500\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.9394]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.9394]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.9299]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.9299]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.9326]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.9326]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.3577]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.3577]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.4980]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.4980]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.7745]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.7745]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.4807]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.4807]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.8399]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.8399]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.4521]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.4521]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.3671]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.3671]], grad_fn=<SigmoidBackward0>)\n",
            "y pred est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    0\n",
            "6    0\n",
            "7    1\n",
            "8    0\n",
            "9    1\n",
            "dtype: int64\n",
            "labels est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "Name: target, dtype: int64\n",
            "y pred est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    0\n",
            "6    0\n",
            "7    1\n",
            "8    0\n",
            "9    1\n",
            "dtype: int64\n",
            "labels est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "Name: target, dtype: int64\n",
            "====> Epoch: 1 Average train loss: 0.9553, train acc: 0.8000, Average val loss: 0.5597, val acc: 0.8000\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.0131]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.0131]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.4690]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.4690]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.5147]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.5147]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.5624]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.5624]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.7516]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.7516]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.9687]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.9687]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.3760]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.3760]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.8055]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.8055]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.1840]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.1840]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.7860]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.7860]], grad_fn=<SigmoidBackward0>)\n",
            "y pred est: 0    1\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    0\n",
            "9    1\n",
            "dtype: int64\n",
            "labels est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "Name: target, dtype: int64\n",
            "y pred est: 0    1\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    0\n",
            "9    1\n",
            "dtype: int64\n",
            "labels est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "Name: target, dtype: int64\n",
            "====> Epoch: 2 Average train loss: 0.7357, train acc: 0.8333, Average val loss: 0.4081, val acc: 0.8333\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.5141]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.5141]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.8954]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.8954]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.8806]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.8806]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.7130]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.7130]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.3749]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.3749]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.0443]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.0443]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.5773]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.5773]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.7245]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.7245]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.9388]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.9388]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.8347]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.8347]], grad_fn=<SigmoidBackward0>)\n",
            "y pred est: 0    1\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "dtype: int64\n",
            "labels est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "Name: target, dtype: int64\n",
            "y pred est: 0    1\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "dtype: int64\n",
            "labels est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "Name: target, dtype: int64\n",
            "====> Epoch: 3 Average train loss: 0.4661, train acc: 0.9231, Average val loss: 0.3058, val acc: 0.9231\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.4147]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.4147]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.7606]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.7606]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.6560]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.6560]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.2759]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.2759]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.0886]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.0886]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.9097]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.9097]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.7980]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.7980]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[0.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.6632]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.6632]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.6831]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.6831]], grad_fn=<SigmoidBackward0>)\n",
            "labels on train:  tensor([[1.]])  labels shape:  torch.Size([1, 1])\n",
            "model_output on train:  tensor([[0.5226]], grad_fn=<SigmoidBackward0>)  model_output shape:  torch.Size([1, 1])  model output:  tensor([[0.5226]], grad_fn=<SigmoidBackward0>)\n",
            "y pred est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "dtype: int64\n",
            "labels est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "Name: target, dtype: int64\n",
            "y pred est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "dtype: int64\n",
            "labels est: 0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    1\n",
            "9    1\n",
            "Name: target, dtype: int64\n",
            "====> Epoch: 4 Average train loss: 0.4085, train acc: 1.0000, Average val loss: 0.2625, val acc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4],\n",
              " [1.7239596901461482,\n",
              "  0.9553316570818424,\n",
              "  0.735698975250125,\n",
              "  0.4661373980343342,\n",
              "  0.40850080624222757],\n",
              " [1.1446754757780582,\n",
              "  0.559705707617104,\n",
              "  0.40805512517690656,\n",
              "  0.30580390579998495,\n",
              "  0.2624692372977734],\n",
              " [0.7499999999999999, 0.8, 0.8333333333333334, 0.923076923076923, 1.0],\n",
              " [0.7499999999999999, 0.8, 0.8333333333333334, 0.923076923076923, 1.0])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SequenceClassifierOutput."
      ],
      "metadata": {
        "id": "wIUaoToFvqzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# PT\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "model.save_pretrained(MODEL)\n",
        "\n",
        "text = \"Good night 😊\"\n",
        "text = preprocess(text)\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)\n",
        "scores = output[0][0].detach().numpy()\n",
        "scores = softmax(scores)\n",
        "\n",
        "# # TF\n",
        "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "# model.save_pretrained(MODEL)\n",
        "\n",
        "# text = \"Good night 😊\"\n",
        "# encoded_input = tokenizer(text, return_tensors='tf')\n",
        "# output = model(encoded_input)\n",
        "# scores = output[0][0].numpy()\n",
        "# scores = softmax(scores)\n",
        "\n",
        "ranking = np.argsort(scores)\n",
        "ranking = ranking[::-1]\n",
        "for i in range(scores.shape[0]):\n",
        "    l = labels[ranking[i]]\n",
        "    s = scores[ranking[i]]\n",
        "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "ETexq_usZRJJ",
        "outputId": "02547c8e-e90a-418f-ceee-61a56153ee0d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-33b2e703bd60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# PT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Good night 😊\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    465\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mContextManagers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_contexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m         \u001b[0;31m# Check first if we are `from_pt`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroberta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_pooling_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaClassificationHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaPooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0madd_pooling_layer\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRobertaLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRobertaLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self} should be used as a decoder model if cross attention is added\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrossattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_embedding_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaIntermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_act\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACT2FN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_act\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# https://github.com/pytorch/pytorch/issues/57109\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGiEitqjYhMM"
      },
      "source": [
        "## Setup Commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaXEQzUiYhMN",
        "outputId": "04bc6652-5a04-410f-e89e-5a6718bdd129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reinitialized existing Git repository in e:/Python Scripts/bci_mouse/DLINtroProject/test/.git/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: remote origin already exists.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Branch 'main' set up to track remote branch 'main' from 'origin'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Switched to a new branch 'main'\n"
          ]
        }
      ],
      "source": [
        "!git init .\n",
        "!git remote add origin https://github.com/ArielFix/DLINtroProject.git\n",
        "!git fetch\n",
        "!git checkout main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMCOjNZtYhMO",
        "outputId": "6843c4b3-0f5c-40c9-fe82-1d8a4e5914f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"This may take a while:\"\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.3; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the 'e:\\Python Scripts\\bci_mouse\\DLINtroProject\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!echo \"This may take a while:\"\n",
        "%pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gck5OX6YhMP"
      },
      "source": [
        "## Troubleshooting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBDeFVQvYhMP",
        "outputId": "a4f92c2c-50c7-49e0-eb50-0fecb2cc84bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synonym Replace: hullo @world, let's see if the #augmentation go! GO! GO! GO!\n",
            "Back Translate: Hello @world, let's see if the #Augmentation work! WALK! WALK! WALK!\n",
            "Random Delete: Hello @world, 's  if  #augmentations work! GO! GO! GO!\n",
            "Random Insertion: Hello @ world, let's see if the #augmentation augmentations work! GO hello! GO! GO!\n",
            "Remove Duplicates: Hello @ world, let's see if the #augmentations work! GO\n",
            "Swap Words: 's @ GO #let Hello see, the if augmentations work GO GO! world!!!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using state Tel Aviv server backend.\n",
            "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Shaiel\n",
            "[nltk_data]     Cohen\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data] Downloading package punkt to C:\\Users\\Shaiel\n",
            "[nltk_data]     Cohen\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to C:\\Users\\Shaiel\n",
            "[nltk_data]     Cohen\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!python test_augs.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25-VVQD8YhMQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.0 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "7645dde2e29746a0cd35ce904051cb398f45ecdefb65fe0e340e36ef16380419"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d936815c1b154b5ca8e42aeaf646afab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_509a92c90728466ba28e51af8715a79f",
              "IPY_MODEL_c223cf911d7b4a95b100eb69896068a9",
              "IPY_MODEL_ddeb3c46b7dc4d0ebee5239d3ba8b95e"
            ],
            "layout": "IPY_MODEL_13aec32f6bb9460ab2ab078964982614"
          }
        },
        "509a92c90728466ba28e51af8715a79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb4e64bf22ba43a7b510ad6e77d6bbd1",
            "placeholder": "​",
            "style": "IPY_MODEL_c3b0c373b1b7499c84742c227f05eaab",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c223cf911d7b4a95b100eb69896068a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_735ef05567674001bf14703f1cb1cbd1",
            "max": 747,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_373f19e1a13040f9a2b89bc5d754f519",
            "value": 747
          }
        },
        "ddeb3c46b7dc4d0ebee5239d3ba8b95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b620a242471149bc9e6faed566d6b55b",
            "placeholder": "​",
            "style": "IPY_MODEL_57b30247bd0e4e2f914710bb599a2258",
            "value": " 747/747 [00:00&lt;00:00, 10.0kB/s]"
          }
        },
        "13aec32f6bb9460ab2ab078964982614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb4e64bf22ba43a7b510ad6e77d6bbd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b0c373b1b7499c84742c227f05eaab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "735ef05567674001bf14703f1cb1cbd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373f19e1a13040f9a2b89bc5d754f519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b620a242471149bc9e6faed566d6b55b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b30247bd0e4e2f914710bb599a2258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56d3d190bcb14afc9cd865b2e2b5f3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f782d946aed4600a9c935d05fd15d96",
              "IPY_MODEL_30920e6f5cc8468b8f55980d7bb2c4aa",
              "IPY_MODEL_7b396d0201b34af9a00ace9e7cb492e8"
            ],
            "layout": "IPY_MODEL_ff4c5897b7e349f5baba621a9e4eae47"
          }
        },
        "1f782d946aed4600a9c935d05fd15d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc15da8855d54626b21d75bd08552be2",
            "placeholder": "​",
            "style": "IPY_MODEL_3716b31c4435471989101a31e44d88c9",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "30920e6f5cc8468b8f55980d7bb2c4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_404e9f2aecd74101b3371ef10881da05",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9637221d318b4d148677bba2289c950c",
            "value": 898822
          }
        },
        "7b396d0201b34af9a00ace9e7cb492e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97c4d61b6bbd40d9a9642d31daaab10f",
            "placeholder": "​",
            "style": "IPY_MODEL_e008e0cf9bad4c21973053cec140900f",
            "value": " 899k/899k [00:00&lt;00:00, 8.85MB/s]"
          }
        },
        "ff4c5897b7e349f5baba621a9e4eae47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc15da8855d54626b21d75bd08552be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3716b31c4435471989101a31e44d88c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "404e9f2aecd74101b3371ef10881da05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9637221d318b4d148677bba2289c950c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97c4d61b6bbd40d9a9642d31daaab10f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e008e0cf9bad4c21973053cec140900f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cba0d261913e40adbe1253a435f8789b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e86880cc40554eabb6584f514359f5c5",
              "IPY_MODEL_5fa96d7ddbef4847a7fa1303a3ce9e24",
              "IPY_MODEL_6dc8356129164b5eac3637fe56d56993"
            ],
            "layout": "IPY_MODEL_58e90c2326ae4450a7c6523f56795348"
          }
        },
        "e86880cc40554eabb6584f514359f5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f999100a02f24850bd3abc3c01fe5ee0",
            "placeholder": "​",
            "style": "IPY_MODEL_cc28870e0fd64cb197a438a1e60e99e8",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "5fa96d7ddbef4847a7fa1303a3ce9e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32363a41fc6242e7b8a95b25e3796e9c",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a813027bb374fe49a5850e314b550d4",
            "value": 456318
          }
        },
        "6dc8356129164b5eac3637fe56d56993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98015b7385cf4dd181cc658d749a115f",
            "placeholder": "​",
            "style": "IPY_MODEL_8b86bf37e1834a8ba8e00b0b7949aa14",
            "value": " 456k/456k [00:00&lt;00:00, 6.45MB/s]"
          }
        },
        "58e90c2326ae4450a7c6523f56795348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f999100a02f24850bd3abc3c01fe5ee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc28870e0fd64cb197a438a1e60e99e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32363a41fc6242e7b8a95b25e3796e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a813027bb374fe49a5850e314b550d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98015b7385cf4dd181cc658d749a115f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b86bf37e1834a8ba8e00b0b7949aa14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "157f8e7ef55344388bec096f850b17a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af71bd6085d9488d82a593291162951e",
              "IPY_MODEL_d130f42a09ad4351aa070860b19393c4",
              "IPY_MODEL_48607fd6f02842e19f4e45297a4be42b"
            ],
            "layout": "IPY_MODEL_e5ef8223d7ad438f8ed50cb96988abe3"
          }
        },
        "af71bd6085d9488d82a593291162951e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6839731f0734ed1ac65eff12bda377d",
            "placeholder": "​",
            "style": "IPY_MODEL_dd93e3cdcb314deabf62b512d8c44546",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "d130f42a09ad4351aa070860b19393c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cc374899a1f4c258c963b662d67bdd7",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_957f6b7fa0f64a7fb135261a2663b8f4",
            "value": 150
          }
        },
        "48607fd6f02842e19f4e45297a4be42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b101244f0c24b65ac46bf9115fadb01",
            "placeholder": "​",
            "style": "IPY_MODEL_6c03ddee5f3e455fa40e268d954e0686",
            "value": " 150/150 [00:00&lt;00:00, 1.98kB/s]"
          }
        },
        "e5ef8223d7ad438f8ed50cb96988abe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6839731f0734ed1ac65eff12bda377d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd93e3cdcb314deabf62b512d8c44546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cc374899a1f4c258c963b662d67bdd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957f6b7fa0f64a7fb135261a2663b8f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b101244f0c24b65ac46bf9115fadb01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c03ddee5f3e455fa40e268d954e0686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57b51a430bf24bd7a4b27dec39547938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1362d98e8e7d47aebe3fe34588332594",
              "IPY_MODEL_98f63b305d394735bf528fbde6c9aeee",
              "IPY_MODEL_4b069ff4bf724d3eab8f4271e3e1341c"
            ],
            "layout": "IPY_MODEL_18d699dd8b814e9e9a77b7703e0b9873"
          }
        },
        "1362d98e8e7d47aebe3fe34588332594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d60773b54db4ef8b6f7f481be256137",
            "placeholder": "​",
            "style": "IPY_MODEL_8f1e56f75f4c46bf970ac66bd2c6b3c5",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "98f63b305d394735bf528fbde6c9aeee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6622edba9e2348bca1a0e13f23cabefe",
            "max": 498679497,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f4562f3c0454c44ae88121018fa5f3c",
            "value": 498679497
          }
        },
        "4b069ff4bf724d3eab8f4271e3e1341c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593562ea9685454f98497a795b69705a",
            "placeholder": "​",
            "style": "IPY_MODEL_e4adc20f63a04807b10bd48554b07d7e",
            "value": " 499M/499M [00:03&lt;00:00, 173MB/s]"
          }
        },
        "18d699dd8b814e9e9a77b7703e0b9873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d60773b54db4ef8b6f7f481be256137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f1e56f75f4c46bf970ac66bd2c6b3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6622edba9e2348bca1a0e13f23cabefe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f4562f3c0454c44ae88121018fa5f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "593562ea9685454f98497a795b69705a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4adc20f63a04807b10bd48554b07d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}