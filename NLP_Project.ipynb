{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArielFix/DLINtroProject/blob/ImportRobertaPreTrained/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "gXXJiRFgYhKz",
        "outputId": "75c7fbd7-3873-45ca-ae31-83ff5cd7c97c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-296801345cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbranch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"git\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rev-parse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--abbrev-ref\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<a href=\"https://colab.research.google.com/github/ArielFix/DLINtroProject/blob/{branch}/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[1;32m    416\u001b[0m                **kwargs).stdout\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    517\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['git', 'rev-parse', '--abbrev-ref', 'HEAD']' returned non-zero exit status 128."
          ]
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "import subprocess\n",
        "\n",
        "branch = subprocess.check_output([\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"]).decode()[:-1]\n",
        "HTML('<a href=\"https://colab.research.google.com/github/ArielFix/DLINtroProject/blob/{branch}/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'.format(branch=branch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpMqyzzkYhLB"
      },
      "source": [
        "## Notes:\n",
        "* Running may require commands in the bottom of the notebook first\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "peWUcuINV7sS"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "\n",
        "# use GPU for computation if possible: Go to RUNTIME -> CHANGE RUNTIME TYPE -> GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "804WKMCAWEe7",
        "outputId": "d7260ba3-6495-4eee-ab4b-59816a26bfd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "train_path = '/content/gdrive/MyDrive/NLP_Project/data/train.csv'\n",
        "test_path = '/content/gdrive/My Drive/NLP_Project/data/test.csv'\n",
        "sample_submission_path = '/content/gdrive/MyDrive/NLP_Project/data/sample_submission.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yAnJ7d3vYqsV"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "#print(train_df.to_string())\n",
        "#print(test_df.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0syMlj9ae_E"
      },
      "source": [
        "**A quick look at our data**\n",
        "Let's look at our data... first, some examples of what is NOT a disaster tweet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byonChzkajoQ",
        "outputId": "19209acd-a2f1-4e60-e2fd-f2e14a898567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What's up man?\n",
            "I love fruits\n",
            "Summer is lovely\n",
            "My car is so fast\n",
            "What a goooooooaaaaaal!!!!!!\n"
          ]
        }
      ],
      "source": [
        "print('\\n' .join(map(str, train_df[train_df[\"target\"] == 0][\"text\"].values[0:5])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM_OM_EScYgJ"
      },
      "source": [
        "And some examples of what is a disaster tweet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_DdvOhrcc8s",
        "outputId": "0ff92969-c5e3-443a-b791-2e580d557e20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
            "Forest fire near La Ronge Sask. Canada\n",
            "All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
            "13,000 people receive #wildfires evacuation orders in California \n",
            "Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n"
          ]
        }
      ],
      "source": [
        "print('\\n' .join(map(str, train_df[train_df[\"target\"] == 1][\"text\"].values[0:5])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5_Jex7SdJdU"
      },
      "source": [
        "The words contained in each tweet are a good indicator of whether they're about a real disaster or not. This is not entirely correct, but it's a great place to start.\n",
        "\n",
        "We'll use scikit-learn's `CountVectorizer` to count the words in each tweet and turn them into data our machine learning model can process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLFGPgObdhfi",
        "outputId": "a676c428-0267-43b5-ff0a-8ac76613cf91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first 5 tweets in the data: \n",
            "\n",
            "[FORBES]: China's Stock Market Crash: Are There Gems In The Rubble?: ChinaÛªs stock market crash this summer ha... http://t.co/Q4grDpAjr5\n",
            "Former Township fire truck being used in Philippines - Langley Times http://t.co/L90dCPV9Zu #Philippines\n",
            "@EnvySeven My beautiful Aquarius queenmy Siren of the cliffs and pretenses of overtures.Please sing this phantom songfor you alone shall\n",
            "FAAN orders evacuation of abandoned aircraft at MMA: FAAN noted that the action had become neces... http://t.co/tlS40nqiPN Via @todayngr\n",
            "Who is bringing the tornadoes and floods. Who is bringing the climate change. God is after America He is plaguing her\n",
            " \n",
            "#FARRAKHAN #QUOTE\n",
            "\n",
            "\n",
            "(1, 77)\n",
            "[[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 1 2 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1\n",
            "  0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 2 1 0 1 1 1 0 0 0 0 0 0\n",
            "  0 0 0 0 1]]\n"
          ]
        }
      ],
      "source": [
        "train_df, val_df = model_selection.train_test_split(train_df)\n",
        "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
        "\n",
        "## let's get counts for the first 5 tweets in the data\n",
        "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])\n",
        "print('The first 5 tweets in the data: \\n')\n",
        "print('\\n' .join(map(str, train_df[\"text\"][0:5])))\n",
        "print('\\n')\n",
        "## we use .todense() here because these vectors are \"sparse\" (only non-zero elements are kept to save space)\n",
        "print(example_train_vectors[0].todense().shape)\n",
        "print(example_train_vectors[0].todense())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usIeYe9Qe-jg"
      },
      "source": [
        "**The above tells us that:**\n",
        "\n",
        "1.   There are 54 unique words (or \"tokens\") in the first five tweets.\n",
        "2.   The first tweet contains only some of those unique tokens - all of the non-zero counts above are the tokens that DO exist in the first tweet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcA5TFkdfjHZ"
      },
      "source": [
        "Now let's create vectors for all of our tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OtIFyab_fit-"
      },
      "outputs": [],
      "source": [
        "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
        "\n",
        "## note that we're NOT using .fit_transform() on test_df. Using just .transform() makes sure\n",
        "# that the tokens in the train vectors are the only ones mapped to the test vectors - \n",
        "# i.e. that the train and test vectors use the same set of tokens.\n",
        "val_vectors = count_vectorizer.transform(val_df[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpPhYkkGf_jl"
      },
      "source": [
        "**Our model**\n",
        "\n",
        "As we mentioned above, we think the words contained in each tweet are a good indicator of whether they're about a real disaster or not. The presence of particular word (or set of words) in a tweet might link directly to whether or not that tweet is real.\n",
        "\n",
        "What we're assuming here is a linear connection. So let's build a linear model and see!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VRwkRi7hgBaA"
      },
      "outputs": [],
      "source": [
        "## Our vectors are really big, so we want to push our model's weights\n",
        "## toward 0 without completely discounting different words - ridge regression \n",
        "## is a good way to do this.\n",
        "clf = linear_model.RidgeClassifier()\n",
        "clf.fit(train_vectors, train_df[\"target\"]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqW_HlFzLYUd",
        "outputId": "609f9890-eec8-452e-9d4a-0ed2f03e350e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7424144609425437"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "val_target = clf.predict(val_vectors)\n",
        "f1_score(y_pred=val_target, y_true=val_df[\"target\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erAJlNvqKglh"
      },
      "source": [
        "Let's test our model and see how well it does on the training data. For this we'll use cross-validation - where we train on a portion of the known data, then validate it with the rest. If we do this several times (with different portions) we can get a good idea for how a particular model or method performs.\n",
        "\n",
        "The metric for this competition is F1, so let's use that here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug_ecfZuKxxE",
        "outputId": "8bf4820b-d6da-41ee-9380-b779a7b95f04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.72796449, 0.73186959, 0.73337637])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "3522czRaPt5B"
      },
      "outputs": [],
      "source": [
        "results = pd.read_csv(sample_submission_path)\n",
        "results.target = clf.predict(count_vectorizer.transform(test_df[\"text\"]))\n",
        "results.to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFJs2yb-PqnQ"
      },
      "source": [
        "![ridge_score.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I42bT7YlK1Q1"
      },
      "source": [
        "The above scores aren't terrible! It looks like our assumption will score roughly 0.65 on the leaderboard. There are lots of ways to potentially improve on this (TFIDF, LSA, LSTM / RNNs, the list is long!) - we will give any of them a shot!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcux5Ux2PP9y"
      },
      "source": [
        "\n",
        "Here's how we could use an RNN to solve the disaster tweets problem:\n",
        "\n",
        "\n",
        "1.   Preprocess the tweet data by tokenizing the text and creating a vocabulary. we \n",
        "may also want to consider applying techniques such as stemming and lemmatization to help reduce the dimensionality of the data.\n",
        "3. Pad the sequences of integers to ensure that all of the tweets have the same length.\n",
        "4. Build an RNN model with an embedding layer, followed by one or more LSTM or GRU layers, and ending with a dense layer for classification.\n",
        "5. Train the model on the disaster tweets data, using binary cross-entropy loss and an optimizer such as Adam.\n",
        "6. Evaluate the model's performance on a held-out test set and fine-tune the model as needed to improve its accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_4anoqqQXpN"
      },
      "source": [
        "We'll may also try and fine-tune: [twitter-roberta-sentiment](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment) for our purposes. If possible within the given schedule and resources. We will also see if we the results from the pre-trained model improve our model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGiEitqjYhMM"
      },
      "source": [
        "## Setup Commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaXEQzUiYhMN",
        "outputId": "04bc6652-5a04-410f-e89e-5a6718bdd129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reinitialized existing Git repository in e:/Python Scripts/bci_mouse/DLINtroProject/test/.git/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: remote origin already exists.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Branch 'main' set up to track remote branch 'main' from 'origin'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Switched to a new branch 'main'\n"
          ]
        }
      ],
      "source": [
        "!git init .\n",
        "!git remote add origin https://github.com/ArielFix/DLINtroProject.git\n",
        "!git fetch\n",
        "!git checkout main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMCOjNZtYhMO",
        "outputId": "6843c4b3-0f5c-40c9-fe82-1d8a4e5914f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"This may take a while:\"\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.3; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the 'e:\\Python Scripts\\bci_mouse\\DLINtroProject\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!echo \"This may take a while:\"\n",
        "%pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gck5OX6YhMP"
      },
      "source": [
        "## Troubleshooting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBDeFVQvYhMP",
        "outputId": "a4f92c2c-50c7-49e0-eb50-0fecb2cc84bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synonym Replace: hullo @world, let's see if the #augmentation go! GO! GO! GO!\n",
            "Back Translate: Hello @world, let's see if the #Augmentation work! WALK! WALK! WALK!\n",
            "Random Delete: Hello @world, 's  if  #augmentations work! GO! GO! GO!\n",
            "Random Insertion: Hello @ world, let's see if the #augmentation augmentations work! GO hello! GO! GO!\n",
            "Remove Duplicates: Hello @ world, let's see if the #augmentations work! GO\n",
            "Swap Words: 's @ GO #let Hello see, the if augmentations work GO GO! world!!!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using state Tel Aviv server backend.\n",
            "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Shaiel\n",
            "[nltk_data]     Cohen\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data] Downloading package punkt to C:\\Users\\Shaiel\n",
            "[nltk_data]     Cohen\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to C:\\Users\\Shaiel\n",
            "[nltk_data]     Cohen\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!python test_augs.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11xfcYs0ajbk",
        "outputId": "d3547679-fe97-4051-a5e0-7d469b409531"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import csv\n",
        "import urllib.request\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "OpBN3F1-agUI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imperting pre-trained roberta:\n",
        "task='sentiment'\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "roberta_model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "roberta_model.save_pretrained(MODEL)\n",
        "\n",
        "def preprocess(text):\n",
        "    new_text = []\n",
        " \n",
        " \n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)"
      ],
      "metadata": {
        "id": "yhMjkW1fa7v5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing roberta model architecture\n",
        "roberta_model.modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne8Bz-j_cpaE",
        "outputId": "1709c435-12bc-4197-995e-d6fb2e4a9498"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.modules of RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing roberta model last layer to adjust the output to the required task\n",
        "\n",
        "roberta_model.classifier.out_proj = nn.Sequential(nn.Linear(in_features=768, out_features=1, bias=True), nn.Sigmoid())\n",
        "\n",
        "roberta_model.modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG1SoXnwcYN9",
        "outputId": "2aa3ffb2-8251-4ea9-d80a-dfab83dbd76c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.modules of RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Sequential(\n",
              "      (0): Linear(in_features=768, out_features=1, bias=True)\n",
              "      (1): Sigmoid()\n",
              "    )\n",
              "  )\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing roberta model parameters - only the classifier can be trained\n",
        "for parameter in roberta_model.parameters():\n",
        "  parameter.requires_grad = False\n",
        "\n",
        "for classifier_parameter in roberta_model.classifier.parameters():\n",
        "  classifier_parameter.requires_grad = True\n",
        "\n",
        "# for parameter in roberta_model.parameters():\n",
        "#   print(parameter.requires_grad)"
      ],
      "metadata": {
        "id": "KQvRopJXghhJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_data = pd.DataFrame()\n",
        "train_text_data[\"text\"] =  train_df['text']\n",
        "train_text_data[\"target\"] = train_df['target']\n",
        "train_text_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "for line in range(0, len(train_text_data['text'])):\n",
        "  train_text_data['text'][line] = preprocess(train_text_data['text'][line])\n",
        "\n",
        "print(\"train text example:\")\n",
        "train_text_data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "IjwCsHVbpeco",
        "outputId": "7ac99c97-f0bc-4b27-af43-adb9586699e5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-0cbc12547971>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_text_data['text'][line] = preprocess(train_text_data['text'][line])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train text example:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target\n",
              "0  [FORBES]: China's Stock Market Crash: Are Ther...       0\n",
              "1  Former Township fire truck being used in Phili...       1\n",
              "2  @user My beautiful Aquarius queenmy Siren of t...       0\n",
              "3  FAAN orders evacuation of abandoned aircraft a...       1\n",
              "4  Who is bringing the tornadoes and floods. Who ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52ca1c1c-b834-490d-b544-4d57b0c02159\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[FORBES]: China's Stock Market Crash: Are Ther...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Former Township fire truck being used in Phili...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user My beautiful Aquarius queenmy Siren of t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FAAN orders evacuation of abandoned aircraft a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who is bringing the tornadoes and floods. Who ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52ca1c1c-b834-490d-b544-4d57b0c02159')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52ca1c1c-b834-490d-b544-4d57b0c02159 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52ca1c1c-b834-490d-b544-4d57b0c02159');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"val text example:\")\n",
        "val_text_data = pd.DataFrame()\n",
        "val_text_data[\"text\"], val_text_data[\"target\"] = val_df[\"text\"], val_df['target']\n",
        "val_text_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "for line in range(0, len(val_text_data['text'])):\n",
        "  val_text_data['text'][line] = preprocess(val_text_data['text'][line])\n",
        "\n",
        "val_text_data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "-8zMzBIT96mh",
        "outputId": "a832ea0b-a5e8-4e4a-af1f-cc5597873f80"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val text example:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-a3275e05f40e>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_text_data['text'][line] = preprocess(val_text_data['text'][line])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target\n",
              "0  3 Years After the Sikh Temple Massacre Hate-Vi...       1\n",
              "1  Pendleton media office said only fire on base ...       1\n",
              "2  IT STARTS A FOREST FIRE THAT CANNOT BE PUT OUT...       1\n",
              "3  James Kunstler: How bad architecture wrecked c...       0\n",
              "4  #science Now that a piece of wreckage from fli...       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d83674a-3021-4edc-a036-6ae04a09843c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3 Years After the Sikh Temple Massacre Hate-Vi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pendleton media office said only fire on base ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IT STARTS A FOREST FIRE THAT CANNOT BE PUT OUT...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>James Kunstler: How bad architecture wrecked c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#science Now that a piece of wreckage from fli...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d83674a-3021-4edc-a036-6ae04a09843c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d83674a-3021-4edc-a036-6ae04a09843c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d83674a-3021-4edc-a036-6ae04a09843c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def estimate_roberta_model_accuracy(model_outputs, labels):\n",
        "  y_preds = torch.zeros(torch.tensor(model_outputs).view(-1,).shape[0], dtype=torch.int64)\n",
        "  print('model_outputs shape: ', torch.tensor(model_outputs).view(-1,))\n",
        "  print('y_preds output shape: ', y_preds)\n",
        "  model_preds = torch.tensor(model_outputs).view(-1,) > 0.5\n",
        "  y_preds[model_preds] = 1\n",
        "  # y_preds = torch.tensor(pd.Series(y_preds.detach())).view(-1,)\n",
        "  \n",
        "  # print('y pred est:', y_preds)\n",
        "  # print('labels est:', labels)\n",
        "\n",
        "  return f1_score(y_pred=y_preds, y_true=labels)\n",
        "\n",
        "def get_roberta_train_data_accuracy(model, data, batch_size = 1):\n",
        "  model.eval()\n",
        "  model_outputs = []\n",
        "  for i in range(0, len(data), batch_size):\n",
        "    if (i + batch_size) > len(data):\n",
        "      break\n",
        "    data_idx = range(i,i+batch_size)\n",
        "    text_data = data['text'][data.index[data_idx]].to_list()\n",
        "    preprocessed_data = tokenizer(text_data, return_tensors='pt', padding=True).to(device)\n",
        "\n",
        "    model_output = roberta_model.forward(**preprocessed_data).logits\n",
        "    preprocessed_data.to('cpu')\n",
        "    print('model output shape: ', model_output, ' and after view: ',model_output.view(-1,).detach())\n",
        "    model_outputs.append(model_output.view(-1,).detach().to('cpu').tolist())\n",
        "  model_train_labels = data['target']\n",
        "  return estimate_roberta_model_accuracy(model_outputs, model_train_labels)\n",
        "\n",
        "\n",
        "\n",
        "def train_roberta_model(roberta_model, train_data, val_data, learning_rate=1e-3, weight_decay=0, batch_size=32, num_epoches=30, check_point_path=None):\n",
        "  \n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(roberta_model.parameters(),\n",
        "                          lr=learning_rate,\n",
        "                          weight_decay=weight_decay)\n",
        "\n",
        "  epoches, train_losses, val_losses = [], [], []\n",
        "  train_accs, val_accs  = [], []\n",
        "  \n",
        "  for epoch in range(0,num_epoches):\n",
        "    roberta_model.train()\n",
        "    model_val_outputs = []\n",
        "    epoch_train_loss = 0\n",
        "    train_iterations_counter = 0\n",
        "    \n",
        "\n",
        "    train_random_order = torch.randperm(len(train_data)).numpy()\n",
        "    val_random_order = torch.randperm(len(val_data)).numpy()\n",
        "    for i in range(0, len(train_data), batch_size):\n",
        "      if (i + batch_size) > len(train_data):\n",
        "        break\n",
        "      train_iterations_counter += 1\n",
        "      data_idx = train_random_order[i:i+batch_size]\n",
        "      labels = train_data['target'][train_data.index[data_idx]].to_list()\n",
        "      labels = torch.tensor([labels], dtype=torch.float32).view(batch_size, 1).to(device)\n",
        "      data = train_data['text'][train_data.index[data_idx]].to_list()\n",
        "      preprocessed_data = tokenizer(data, return_tensors='pt', padding=True).to(device)\n",
        "      # print('labels on train: ', labels, ' labels shape: ', labels.shape)\n",
        "      model_output = roberta_model.forward(**preprocessed_data).logits\n",
        "      # print('model_output on train: ', model_output, ' model_output shape: ', model_output.shape, ' model output: ', model_output)\n",
        "      loss = criterion(model_output, labels)                   # compute the total loss\n",
        "      loss.backward()                      # compute updates for each parameter\n",
        "      optimizer.step()                      # make the updates for each parameter\n",
        "      optimizer.zero_grad() \n",
        "      preprocessed_data.to('cpu')\n",
        "      epoch_train_loss += loss.item()/batch_size\n",
        "    train_losses.append(epoch_train_loss/train_iterations_counter)\n",
        "    train_accs.append(get_roberta_train_data_accuracy(roberta_model, train_data, batch_size))\n",
        "\n",
        "    roberta_model.eval()\n",
        "    val_iterations_counter = 0\n",
        "    epoch_val_loss = 0\n",
        "    for i in range(0, len(val_data), batch_size):\n",
        "      if (i + batch_size) > len(val_data):\n",
        "        break\n",
        "      val_iterations_counter += 1\n",
        "      data_idx = range(i,i+batch_size)\n",
        "      labels = val_data['target'][val_data.index[data_idx]].to_list()\n",
        "      labels = torch.tensor([labels], dtype=torch.float32).view(batch_size, 1).to(device)\n",
        "      data = val_data['text'][val_data.index[data_idx]].to_list()\n",
        "      preprocessed_data = tokenizer(data, return_tensors='pt', padding=True).to(device)\n",
        "\n",
        "      model_output = roberta_model.forward(**preprocessed_data).logits\n",
        "      loss = criterion(model_output, labels)                   # compute the total loss\n",
        "\n",
        "      preprocessed_data.to('cpu')\n",
        "      labels.to('cpu')\n",
        "      model_val_outputs.append(model_output.view(-1,).detach().to('cpu').tolist())\n",
        "       \n",
        "      # print(model_output.logits.detach().numpy())\n",
        "      epoch_val_loss += loss.item()/batch_size\n",
        "\n",
        "    model_val_labels = val_data['target']\n",
        "    val_losses.append(epoch_val_loss/ val_iterations_counter)\n",
        "    epoches.append(epoch)\n",
        "    val_acc_estimation = estimate_roberta_model_accuracy(model_val_outputs, model_val_labels)\n",
        "    val_accs.append(val_acc_estimation)\n",
        "    print(f\"====> Epoch: {epoch} Average train loss: {train_losses[epoch]:.4f}, train acc: {train_accs[epoch]:.4f}, Average val loss: {val_losses[epoch]:.4f}, val acc: {val_accs[epoch]:.4f}\")\n",
        "  \n",
        "  return epoches, train_losses, val_losses, train_accs, val_accs\n",
        "\n",
        "def plot_learning_curve(epoches, train_losses, val_losses, train_accs, val_accs):\n",
        "    \"\"\"\n",
        "    Plot the learning curve.\n",
        "    \"\"\"\n",
        "    plt.title(\"Learning Curve: Loss per epoch\")\n",
        "    plt.plot(epoches, train_losses, label=\"Train\")\n",
        "    plt.plot(epoches, val_losses, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(['Train', 'Train'])\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Learning Curve: Accuracy per epoch\")\n",
        "    plt.plot(epoches, train_accs, label=\"Train\")\n",
        "    plt.plot(epoches, val_accs, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(['Train', 'Train'])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "kk2y4gZ8rg-f"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "train_data_try = train_text_data[0:10]\n",
        "# train_data =  torch.utils.data.DataLoader(train_text.to_list(), batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "# val_data = torch.utils.data.DataLoader(train_text.to_list(), batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "device = 'cpu'\n",
        "roberta_model.to(device)\n",
        "try_overfit = train_roberta_model(roberta_model, train_data_try, train_data_try, learning_rate=1e-3, weight_decay=0, batch_size=5, num_epoches=6, check_point_path=None)\n",
        "plot_learning_curve(*try_overfit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JdfhLYFs3Ms-",
        "outputId": "174cdcac-aee7-4d7e-ea65-ef8f98551271"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model output shape:  tensor([[0.0507],\n",
            "        [0.8309],\n",
            "        [0.0124],\n",
            "        [0.9111],\n",
            "        [0.0301]], grad_fn=<SigmoidBackward0>)  and after view:  tensor([0.0507, 0.8309, 0.0124, 0.9111, 0.0301])\n",
            "model output shape:  tensor([[0.8490],\n",
            "        [0.0853],\n",
            "        [0.6405],\n",
            "        [0.9444],\n",
            "        [0.9846]], grad_fn=<SigmoidBackward0>)  and after view:  tensor([0.8490, 0.0853, 0.6405, 0.9444, 0.9846])\n",
            "model_outputs shape:  tensor([0.0507, 0.8309, 0.0124, 0.9111, 0.0301, 0.8490, 0.0853, 0.6405, 0.9444,\n",
            "        0.9846])\n",
            "y_preds output shape:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "model_outputs shape:  tensor([0.0507, 0.8309, 0.0124, 0.9111, 0.0301, 0.8490, 0.0853, 0.6405, 0.9444,\n",
            "        0.9846])\n",
            "y_preds output shape:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "====> Epoch: 0 Average train loss: 0.0396, train acc: 1.0000, Average val loss: 0.0229, val acc: 1.0000\n",
            "model output shape:  tensor([[0.1467],\n",
            "        [0.9563],\n",
            "        [0.0141],\n",
            "        [0.9807],\n",
            "        [0.0869]], grad_fn=<SigmoidBackward0>)  and after view:  tensor([0.1467, 0.9563, 0.0141, 0.9807, 0.0869])\n",
            "model output shape:  tensor([[0.9711],\n",
            "        [0.1677],\n",
            "        [0.9387],\n",
            "        [0.9806],\n",
            "        [0.9981]], grad_fn=<SigmoidBackward0>)  and after view:  tensor([0.9711, 0.1677, 0.9387, 0.9806, 0.9981])\n",
            "model_outputs shape:  tensor([0.1467, 0.9563, 0.0141, 0.9807, 0.0869, 0.9711, 0.1677, 0.9387, 0.9806,\n",
            "        0.9981])\n",
            "y_preds output shape:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "model_outputs shape:  tensor([0.1467, 0.9563, 0.0141, 0.9807, 0.0869, 0.9711, 0.1677, 0.9387, 0.9806,\n",
            "        0.9981])\n",
            "y_preds output shape:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "====> Epoch: 1 Average train loss: 0.0348, train acc: 1.0000, Average val loss: 0.0125, val acc: 1.0000\n",
            "model output shape:  tensor([[0.0906],\n",
            "        [0.9173],\n",
            "        [0.0074],\n",
            "        [0.9693],\n",
            "        [0.0534]], grad_fn=<SigmoidBackward0>)  and after view:  tensor([0.0906, 0.9173, 0.0074, 0.9693, 0.0534])\n",
            "model output shape:  tensor([[0.9725],\n",
            "        [0.0423],\n",
            "        [0.9520],\n",
            "        [0.9697],\n",
            "        [0.9985]], grad_fn=<SigmoidBackward0>)  and after view:  tensor([0.9725, 0.0423, 0.9520, 0.9697, 0.9985])\n",
            "model_outputs shape:  tensor([0.0906, 0.9173, 0.0074, 0.9693, 0.0534, 0.9725, 0.0423, 0.9520, 0.9697,\n",
            "        0.9985])\n",
            "y_preds output shape:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "model_outputs shape:  tensor([0.0906, 0.9173, 0.0074, 0.9693, 0.0534, 0.9725, 0.0423, 0.9520, 0.9697,\n",
            "        0.9985])\n",
            "y_preds output shape:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "====> Epoch: 2 Average train loss: 0.0259, train acc: 1.0000, Average val loss: 0.0085, val acc: 1.0000\n",
            "model output shape:  tensor([[0.0932],\n",
            "        [0.9497],\n",
            "        [0.0064],\n",
            "        [0.9837],\n",
            "        [0.0569]], grad_fn=<SigmoidBackward0>)  and after view:  tensor([0.0932, 0.9497, 0.0064, 0.9837, 0.0569])\n",
            "model output shape:  tensor([[0.9851],\n",
            "        [0.0337],\n",
            "        [0.9769],\n",
            "        [0.9815],\n",
            "        [0.9993]], grad_fn=<SigmoidBackward0>)  and after view:  tensor([0.9851, 0.0337, 0.9769, 0.9815, 0.9993])\n",
            "model_outputs shape:  tensor([0.0932, 0.9497, 0.0064, 0.9837, 0.0569, 0.9851, 0.0337, 0.9769, 0.9815,\n",
            "        0.9993])\n",
            "y_preds output shape:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "model_outputs shape:  tensor([0.0932, 0.9497, 0.0064, 0.9837, 0.0569, 0.9851, 0.0337, 0.9769, 0.9815,\n",
            "        0.9993])\n",
            "y_preds output shape:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "====> Epoch: 3 Average train loss: 0.0158, train acc: 1.0000, Average val loss: 0.0065, val acc: 1.0000\n",
            "model output shape:  tensor([[0.1658],\n",
            "        [0.9868],\n",
            "        [0.0066],\n",
            "        [0.9958],\n",
            "        [0.0998]], grad_fn=<SigmoidBackward0>)  and after view:  tensor([0.1658, 0.9868, 0.0066, 0.9958, 0.0998])\n",
            "model output shape:  tensor([[0.9954],\n",
            "        [0.0499],\n",
            "        [0.9941],\n",
            "        [0.9930],\n",
            "        [0.9998]], grad_fn=<SigmoidBackward0>)  and after view:  tensor([0.9954, 0.0499, 0.9941, 0.9930, 0.9998])\n",
            "model_outputs shape:  tensor([0.1658, 0.9868, 0.0066, 0.9958, 0.0998, 0.9954, 0.0499, 0.9941, 0.9930,\n",
            "        0.9998])\n",
            "y_preds output shape:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "model_outputs shape:  tensor([0.1658, 0.9868, 0.0066, 0.9958, 0.0998, 0.9954, 0.0499, 0.9941, 0.9930,\n",
            "        0.9998])\n",
            "y_preds output shape:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "====> Epoch: 4 Average train loss: 0.0189, train acc: 1.0000, Average val loss: 0.0076, val acc: 1.0000\n",
            "model output shape:  tensor([[0.1439],\n",
            "        [0.9881],\n",
            "        [0.0034],\n",
            "        [0.9961],\n",
            "        [0.0744]], grad_fn=<SigmoidBackward0>)  and after view:  tensor([0.1439, 0.9881, 0.0034, 0.9961, 0.0744])\n",
            "model output shape:  tensor([[0.9968],\n",
            "        [0.0163],\n",
            "        [0.9964],\n",
            "        [0.9908],\n",
            "        [0.9999]], grad_fn=<SigmoidBackward0>)  and after view:  tensor([0.9968, 0.0163, 0.9964, 0.9908, 0.9999])\n",
            "model_outputs shape:  tensor([0.1439, 0.9881, 0.0034, 0.9961, 0.0744, 0.9968, 0.0163, 0.9964, 0.9908,\n",
            "        0.9999])\n",
            "y_preds output shape:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "model_outputs shape:  tensor([0.1439, 0.9881, 0.0034, 0.9961, 0.0744, 0.9968, 0.0163, 0.9964, 0.9908,\n",
            "        0.9999])\n",
            "y_preds output shape:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "====> Epoch: 5 Average train loss: 0.0119, train acc: 1.0000, Average val loss: 0.0057, val acc: 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25-VVQD8YhMQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.0 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "7645dde2e29746a0cd35ce904051cb398f45ecdefb65fe0e340e36ef16380419"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}