{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxKAFyDDN1afxFwPu4777U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArielFix/DLINtroProject/blob/NNModel/LSTM_Model_aug_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import string \n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split #Library for Splitting Dataset\n",
        "from sklearn import metrics\n",
        "\n",
        "#Libraries for NN\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout"
      ],
      "metadata": {
        "id": "ABS6e1eeU2F5"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "train_data_path = '/content/gdrive/MyDrive/IDL_Assignments/NLP_Project/data/augmented_train.csv'\n",
        "test_data_path = '/content/gdrive/My Drive/IDL_Assignments/NLP_Project/data/test.csv'\n",
        "submission_path = '/content/gdrive/MyDrive/IDL_Assignments/NLP_Project/data/sample_submission.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml1zRj8hQvEO",
        "outputId": "b177c5e1-3a24-429b-cf72-afa7f0758ffe"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(train_data_path)"
      ],
      "metadata": {
        "id": "jQYb9W5gti9E"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def toclean_text(text):\n",
        "\n",
        "    \n",
        "    clean_text = [char for char in text if char not in string.punctuation]\n",
        "   \n",
        "    clean_text = ''.join(clean_text)\n",
        "    \n",
        "        \n",
        "    return clean_text"
      ],
      "metadata": {
        "id": "bsnxUkk5PsB_"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['clean_text'] = train_data['text'].apply(toclean_text) #This line gives the text without punctuation"
      ],
      "metadata": {
        "id": "Cod3oVFzS7VC"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More pre-processing must be done! such as replace abbreviations with the original word, remove URLs, remove numbers, remove emojis..etc..."
      ],
      "metadata": {
        "id": "QPGUR_YBuzBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "abbreviations = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"â‚¬\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\", \n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "    \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\", \n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\n",
        "    \"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\",\n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retweet\", \n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retweet\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "    \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\", \n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\"\n",
        "}"
      ],
      "metadata": {
        "id": "QeI2P1jzR0Mp"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all URLs, replace by URL\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'URL',text)\n",
        "\n",
        "# Remove HTML beacon\n",
        "def remove_HTML(text):\n",
        "    html=re.compile(r'<.*?>')\n",
        "    return html.sub(r'',text)\n",
        "\n",
        "# Remove non printable characters\n",
        "def remove_not_ASCII(text):\n",
        "    text = ''.join([word for word in text if word in string.printable])\n",
        "    return text\n",
        "\n",
        "# Change an abbreviation by its true meaning\n",
        "def word_abbrev(word):\n",
        "    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word\n",
        "\n",
        "# Replace all abbreviations\n",
        "def replace_abbrev(text):\n",
        "    string = \"\"\n",
        "    for word in text.split():\n",
        "        string += word_abbrev(word) + \" \"        \n",
        "    return string\n",
        "\n",
        "# Remove @ and mention, replace by USER\n",
        "def remove_mention(text):\n",
        "    at=re.compile(r'@\\S+')\n",
        "    return at.sub(r'USER',text)\n",
        "\n",
        "# Remove numbers, replace it by NUMBER\n",
        "def remove_number(text):\n",
        "    num = re.compile(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n",
        "    return num.sub(r'NUMBER', text)\n",
        "\n",
        "# Remove all emojis, replace by EMOJI\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'EMOJI', text)\n",
        "\n",
        "# Replace some others smileys with SADFACE\n",
        "def transcription_sad(text):\n",
        "    eyes = \"[8:=;]\"\n",
        "    nose = \"['`\\-]\"\n",
        "    smiley = re.compile(r'[8:=;][\\'\\-]?[(\\\\/]')\n",
        "    return smiley.sub(r'SADFACE', text)\n",
        "\n",
        "# Replace some smileys with SMILE\n",
        "def transcription_smile(text):\n",
        "    eyes = \"[8:=;]\"\n",
        "    nose = \"['`\\-]\"\n",
        "    smiley = re.compile(r'[8:=;][\\'\\-]?[)dDp]')\n",
        "    #smiley = re.compile(r'#{eyes}#{nose}[)d]+|[)d]+#{nose}#{eyes}/i')\n",
        "    return smiley.sub(r'SMILE', text)\n",
        "\n",
        "# Replace <3 with HEART\n",
        "def transcription_heart(text):\n",
        "    heart = re.compile(r'<3')\n",
        "    return heart.sub(r'HEART', text)"
      ],
      "metadata": {
        "id": "X-7-Ip-wR5In"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet(text):\n",
        "    \n",
        "    # Remove non text\n",
        "    text = remove_URL(text)\n",
        "    text = remove_HTML(text)\n",
        "    text = remove_not_ASCII(text)\n",
        "    \n",
        "    # replace abbreviations, @ and number\n",
        "    text = replace_abbrev(text)  \n",
        "    text = remove_mention(text)\n",
        "    text = remove_number(text)\n",
        "    \n",
        "    # Remove emojis / smileys\n",
        "    text = remove_emoji(text)\n",
        "    text = transcription_sad(text)\n",
        "    text = transcription_smile(text)\n",
        "    text = transcription_heart(text)\n",
        "  \n",
        "    return text"
      ],
      "metadata": {
        "id": "oK63P7viR8x3"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = 64\n",
        "max_features=5000\n",
        "tokenizer=Tokenizer(num_words=max_features,split=' ')\n",
        "tokenizer.fit_on_texts(train_data['clean_text'].values)\n",
        "X = tokenizer.texts_to_sequences(train_data['clean_text'].values)\n",
        "X = pad_sequences(X, maxlen = l)"
      ],
      "metadata": {
        "id": "9e3u1NSyv3ji"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model-"
      ],
      "metadata": {
        "id": "SZLKZ7jtwwju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = train_data['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 59) #Split arrays or matrices into random train and test subsets.\n"
      ],
      "metadata": {
        "id": "ps7Lm2WavR3S"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model explanation -\n",
        "This is a code that creates a deep learning model for binary classification using the Keras library in Python. The model is a sequential model, which means that the layers are added one after the other in a linear stack. The model is designed to classify tweets as either disaster-related or not.\n",
        "\n",
        "Embedding layer: The first layer of the model is an Embedding layer. This layer maps each word in the input sequence to a dense vector of fixed size, called the embedding vector. The embed_dim argument specifies the size of the embedding vector, in this case, it is 32. The input_length argument specifies the length of the input sequence, in this case, it is X.shape[1]. The max_features argument specifies the number of unique words in the vocabulary, which is used to initialize the weights of the embedding layer.\n",
        "\n",
        "Dropout layer: The second layer of the model is a Dropout layer. This layer randomly sets input units to 0 with a frequency of 0.2 at each step during training time, which helps prevent overfitting.\n",
        "\n",
        "LSTM layer: The third layer of the model is an LSTM layer. This layer is a type of Recurrent Neural Network (RNN) that is well-suited for processing sequences of data. The lstm_out argument specifies the size of the output of the LSTM layer, in this case, it is 32. The dropout and recurrent_dropout arguments specify the dropout rates for the LSTM layer.\n",
        "\n",
        "Dense layer: The fourth and final layer of the model is a Dense layer with one output node and a sigmoid activation function. This layer is used to make the binary classification by producing a probability value between 0 and 1, where values close to 0 correspond to class 0 (not disaster-related) and values close to 1 correspond to class 1 (disaster-related).\n",
        "\n",
        "Compiling the model: The model is compiled using the binary_crossentropy loss function, which is suitable for binary classification problems, and the Adam optimizer with a learning rate of 0.002. The metrics argument specifies that accuracy will be used as the evaluation metric.\n",
        "\n",
        "Finally, the model.summary() function call outputs a summary of the model architecture and its parameters, which can be useful for understanding the structure of the model."
      ],
      "metadata": {
        "id": "W-Ejx4QYtFOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 64 \n",
        "lstm_out = 64 #output_dim: Dimension of embedding vector\n",
        "model = Sequential() #a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
        "model.add(Embedding(max_features, embed_dim, input_length = X.shape[1])) #using embedding better then one-hot in the cases where mose indices are zero\n",
        "model.add(Dropout(0.2)) #Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\n",
        "model.add(LSTM(lstm_out, dropout=0.2, return_sequences=True,recurrent_dropout=0.4))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(lstm_out,dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "adam = optimizers.Adam(learning_rate=0.003)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiL6BkEXwKcA",
        "outputId": "eb9e0f25-3add-44f9-b74e-050839255ece"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 64, 64)            320000    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64, 64)            0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64, 64)            33024     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64, 64)            0         \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 386,113\n",
            "Trainable params: 386,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs = 5, batch_size=30, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NanK1ZL3yyHi",
        "outputId": "6824dbf0-a822-4068-c878-11dc04f4b1a0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1333/1333 [==============================] - 365s 274ms/step - loss: 0.1403 - accuracy: 0.9424 - val_loss: 0.1705 - val_accuracy: 0.9341\n",
            "Epoch 2/5\n",
            "1333/1333 [==============================] - 350s 262ms/step - loss: 0.1095 - accuracy: 0.9552 - val_loss: 0.1587 - val_accuracy: 0.9423\n",
            "Epoch 3/5\n",
            "1333/1333 [==============================] - 352s 264ms/step - loss: 0.0899 - accuracy: 0.9622 - val_loss: 0.1783 - val_accuracy: 0.9422\n",
            "Epoch 4/5\n",
            "1333/1333 [==============================] - 355s 266ms/step - loss: 0.0791 - accuracy: 0.9674 - val_loss: 0.1824 - val_accuracy: 0.9452\n",
            "Epoch 5/5\n",
            "1333/1333 [==============================] - 352s 264ms/step - loss: 0.0745 - accuracy: 0.9695 - val_loss: 0.1693 - val_accuracy: 0.9460\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc54636c7f0>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test).round()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYCdTXy-0xJx",
        "outputId": "c49135a1-7129-4797-d574-92d8fa365a4e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "417/417 [==============================] - 16s 36ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "M1_CrRIfGl76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = round(metrics.accuracy_score(y_train,model.predict(X_train).round())*100)\n",
        "train_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDOUBIebGnPq",
        "outputId": "c4ecd2a0-14dd-40c0-cfa5-6f8f09ad89e6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1249/1249 [==============================] - 46s 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy  is  : ', (metrics.accuracy_score(y_test, y_pred)))\n",
        "print('Recall  is    : ', (metrics.recall_score(y_test, y_pred)))\n",
        "print('Precision  is : ', (metrics.precision_score(y_test, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWcbVXG1Gnxm",
        "outputId": "21b03f0a-ee45-4840-f2c5-6a09f90eba14"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  is  :  0.9460331757111762\n",
            "Recall  is    :  0.9158894645941278\n",
            "Precision  is :  0.9580849141824752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission"
      ],
      "metadata": {
        "id": "uHQMSVGqS0Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(test_data_path)"
      ],
      "metadata": {
        "id": "3_P-Q0lQS0jB"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "geh6pjZ7trHO"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['clean_text'] = test_data['text'].apply(toclean_text)\n",
        "test_data[\"clean_text\"] = test_data[\"clean_text\"].apply(clean_tweet)"
      ],
      "metadata": {
        "id": "GXcsxik53vPa"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(train_data['clean_text'].values)\n",
        "test_token = tokenizer.texts_to_sequences(test_data['clean_text'].values)\n",
        "test_token = pad_sequences(test_token, maxlen =l)"
      ],
      "metadata": {
        "id": "GN6vouuSGTcM"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "embed_dim = 128\n",
        "lstm_out = 128\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, return_sequences=True,recurrent_dropout=0.4))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(lstm_out,dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "adam = optimizers.Adam(learning_rate=2e-3)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\n",
        "print(model.summary())\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cv-L7ZBpGT5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "metadata": {
        "id": "UwU6Yks8GbSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.fit(X,y, epochs = 12,validation_split = 0.3 ,callbacks=[es_callback], batch_size=64)"
      ],
      "metadata": {
        "id": "VfzpyjouGc6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model.predict(test_token).round()\n",
        "submission = pd.read_csv(submission_path)\n",
        "submission['target'] = np.round(y_hat).astype('int')\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "EQGwDgqcGe8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448d5cff-c7c7-4e67-b41a-96ab6a6dd582"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102/102 [==============================] - 5s 49ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "5J8uqdrypXQ5",
        "outputId": "c9f72cf1-f484-4ade-a05c-5452d6485c8a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4dc5a629-4393-4b90-bf7e-8653087a945a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4dc5a629-4393-4b90-bf7e-8653087a945a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"arielfixler\",\"key\":\"d1f8d7cc349ae4484d6617532b9e8a93\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n"
      ],
      "metadata": {
        "id": "9Qv7GrL5pdfR"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c nlp-getting-started -f submission.csv -m \"Message\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgjPetNZpkmo",
        "outputId": "8e574ee4-6ac8-4ca3-8142-b51916d08310"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "100% 22.2k/22.2k [00:00<00:00, 101kB/s]\n",
            "Successfully submitted to Natural Language Processing with Disaster Tweets"
          ]
        }
      ]
    }
  ]
}