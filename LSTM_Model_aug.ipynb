{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/K1M00baKyFZll6uOxBIZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArielFix/DLINtroProject/blob/NNModel/LSTM_Model_aug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Natural Language Processing with Disaster Tweets task can be considered a complex task for several reasons:\n",
        "\n",
        "Unstructured data: The data for this task consists of unstructured text data in the form of tweets, which can be messy, inconsistent, and contain misspelled words, slang, and emoticons. This makes preprocessing and cleaning the data a challenging task.\n",
        "\n",
        "Handling imbalanced classes: In the disaster tweets task, the number of positive (disaster-related) tweets is much lower than the number of negative (not disaster-related) tweets. This creates an imbalanced dataset, which can make it difficult for the model to accurately classify disaster-related tweets.\n",
        "\n",
        "Ambiguous and misleading information: Tweets can contain misleading or ambiguous information, which makes it challenging for the model to accurately classify them as disaster-related or not. For example, a tweet may contain disaster-related keywords but not actually be related to a disaster.\n",
        "\n",
        "Dealing with multiple languages: The data for this task can contain tweets written in different languages, making it challenging for the model to accurately classify them.\n",
        "\n",
        "Sentiment analysis: The task requires the model to classify tweets based on their sentiment, which can be difficult due to the complex nature of human emotion and the subjectivity of sentiment analysis."
      ],
      "metadata": {
        "id": "9MfALxQ5sfph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTMs are well-suited for the Natural Language Processing with Disaster Tweets task for several reasons:\n",
        "\n",
        "Contextual understanding: LSTMs are able to maintain context and understand the relationships between words in a sentence, making them well-suited for NLP tasks that require the model to understand the meaning of text. This is particularly important in the context of disaster tweets, where the model needs to be able to understand the context of the tweet in order to determine whether it is related to a disaster or not.\n",
        "\n",
        "Handling sequences: LSTMs are designed to handle sequences of data, making them well-suited for text classification tasks where the model needs to consider the order of words in a sentence. In the disaster tweets task, the model needs to understand the order of words in a tweet in order to determine its meaning and classify it as disaster-related or not.\n",
        "\n",
        "Dealing with unknown words: LSTMs are able to learn and handle words that they have not seen before, making them well-suited for tasks like disaster tweet classification where the model may encounter words that it has not seen before.\n",
        "\n",
        "Fine-tuning: LSTMs can be fine-tuned for specific NLP tasks, making them a versatile tool for text classification. This is particularly useful in the context of disaster tweets, where the model needs to be able to classify tweets based on their content.\n",
        "\n",
        "Overall, the ability of LSTMs to maintain context, handle sequences of data, deal with unknown words, and be fine-tuned for specific NLP tasks make them a good choice for the Natural Language Processing with Disaster Tweets task."
      ],
      "metadata": {
        "id": "uktnufWvsiNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import string \n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split #Library for Splitting Dataset\n",
        "from sklearn import metrics\n",
        "\n",
        "#Libraries for NN\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout"
      ],
      "metadata": {
        "id": "ABS6e1eeU2F5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "train_data_path = '/content/gdrive/MyDrive/IDL_Assignments/NLP_Project/data/augmented_train.csv'\n",
        "test_data_path = '/content/gdrive/My Drive/IDL_Assignments/NLP_Project/data/test.csv'\n",
        "submission_path = '/content/gdrive/MyDrive/IDL_Assignments/NLP_Project/data/sample_submission.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml1zRj8hQvEO",
        "outputId": "3981d5e2-c8f3-4760-b932-1f71a8ed6e2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(train_data_path)"
      ],
      "metadata": {
        "id": "jQYb9W5gti9E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def toclean_text(text):\n",
        "\n",
        "    \n",
        "    clean_text = [char for char in text if char not in string.punctuation]\n",
        "   \n",
        "    clean_text = ''.join(clean_text)\n",
        "    \n",
        "        \n",
        "    return clean_text"
      ],
      "metadata": {
        "id": "bsnxUkk5PsB_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['clean_text'] = train_data['text'].apply(toclean_text) #This line gives the text without punctuation"
      ],
      "metadata": {
        "id": "Cod3oVFzS7VC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More pre-processing must be done! such as replace abbreviations with the original word, remove URLs, remove numbers, remove emojis..etc..."
      ],
      "metadata": {
        "id": "QPGUR_YBuzBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "abbreviations = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"â‚¬\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\", \n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "    \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\", \n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\n",
        "    \"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\",\n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retweet\", \n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retweet\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "    \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\", \n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\"\n",
        "}"
      ],
      "metadata": {
        "id": "QeI2P1jzR0Mp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all URLs, replace by URL\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'URL',text)\n",
        "\n",
        "# Remove HTML beacon\n",
        "def remove_HTML(text):\n",
        "    html=re.compile(r'<.*?>')\n",
        "    return html.sub(r'',text)\n",
        "\n",
        "# Remove non printable characters\n",
        "def remove_not_ASCII(text):\n",
        "    text = ''.join([word for word in text if word in string.printable])\n",
        "    return text\n",
        "\n",
        "# Change an abbreviation by its true meaning\n",
        "def word_abbrev(word):\n",
        "    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word\n",
        "\n",
        "# Replace all abbreviations\n",
        "def replace_abbrev(text):\n",
        "    string = \"\"\n",
        "    for word in text.split():\n",
        "        string += word_abbrev(word) + \" \"        \n",
        "    return string\n",
        "\n",
        "# Remove @ and mention, replace by USER\n",
        "def remove_mention(text):\n",
        "    at=re.compile(r'@\\S+')\n",
        "    return at.sub(r'USER',text)\n",
        "\n",
        "# Remove numbers, replace it by NUMBER\n",
        "def remove_number(text):\n",
        "    num = re.compile(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n",
        "    return num.sub(r'NUMBER', text)\n",
        "\n",
        "# Remove all emojis, replace by EMOJI\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'EMOJI', text)\n",
        "\n",
        "# Replace some others smileys with SADFACE\n",
        "def transcription_sad(text):\n",
        "    eyes = \"[8:=;]\"\n",
        "    nose = \"['`\\-]\"\n",
        "    smiley = re.compile(r'[8:=;][\\'\\-]?[(\\\\/]')\n",
        "    return smiley.sub(r'SADFACE', text)\n",
        "\n",
        "# Replace some smileys with SMILE\n",
        "def transcription_smile(text):\n",
        "    eyes = \"[8:=;]\"\n",
        "    nose = \"['`\\-]\"\n",
        "    smiley = re.compile(r'[8:=;][\\'\\-]?[)dDp]')\n",
        "    #smiley = re.compile(r'#{eyes}#{nose}[)d]+|[)d]+#{nose}#{eyes}/i')\n",
        "    return smiley.sub(r'SMILE', text)\n",
        "\n",
        "# Replace <3 with HEART\n",
        "def transcription_heart(text):\n",
        "    heart = re.compile(r'<3')\n",
        "    return heart.sub(r'HEART', text)"
      ],
      "metadata": {
        "id": "X-7-Ip-wR5In"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet(text):\n",
        "    \n",
        "    # Remove non text\n",
        "    text = remove_URL(text)\n",
        "    text = remove_HTML(text)\n",
        "    text = remove_not_ASCII(text)\n",
        "    \n",
        "    # replace abbreviations, @ and number\n",
        "    text = replace_abbrev(text)  \n",
        "    text = remove_mention(text)\n",
        "    text = remove_number(text)\n",
        "    \n",
        "    # Remove emojis / smileys\n",
        "    text = remove_emoji(text)\n",
        "    text = transcription_sad(text)\n",
        "    text = transcription_smile(text)\n",
        "    text = transcription_heart(text)\n",
        "  \n",
        "    return text"
      ],
      "metadata": {
        "id": "oK63P7viR8x3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l =50\n",
        "max_features=5000\n",
        "tokenizer=Tokenizer(num_words=max_features,split=' ')\n",
        "tokenizer.fit_on_texts(train_data['clean_text'].values)\n",
        "X = tokenizer.texts_to_sequences(train_data['clean_text'].values)\n",
        "X = pad_sequences(X, maxlen =l)"
      ],
      "metadata": {
        "id": "9e3u1NSyv3ji"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model-"
      ],
      "metadata": {
        "id": "SZLKZ7jtwwju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = train_data['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state =41) #Split arrays or matrices into random train and test subsets.\n"
      ],
      "metadata": {
        "id": "ps7Lm2WavR3S"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model explanation -\n",
        "This is a code that creates a deep learning model for binary classification using the Keras library in Python. The model is a sequential model, which means that the layers are added one after the other in a linear stack. The model is designed to classify tweets as either disaster-related or not.\n",
        "\n",
        "Embedding layer: The first layer of the model is an Embedding layer. This layer maps each word in the input sequence to a dense vector of fixed size, called the embedding vector. The embed_dim argument specifies the size of the embedding vector, in this case, it is 32. The input_length argument specifies the length of the input sequence, in this case, it is X.shape[1]. The max_features argument specifies the number of unique words in the vocabulary, which is used to initialize the weights of the embedding layer.\n",
        "\n",
        "Dropout layer: The second layer of the model is a Dropout layer. This layer randomly sets input units to 0 with a frequency of 0.2 at each step during training time, which helps prevent overfitting.\n",
        "\n",
        "LSTM layer: The third layer of the model is an LSTM layer. This layer is a type of Recurrent Neural Network (RNN) that is well-suited for processing sequences of data. The lstm_out argument specifies the size of the output of the LSTM layer, in this case, it is 32. The dropout and recurrent_dropout arguments specify the dropout rates for the LSTM layer.\n",
        "\n",
        "Dense layer: The fourth and final layer of the model is a Dense layer with one output node and a sigmoid activation function. This layer is used to make the binary classification by producing a probability value between 0 and 1, where values close to 0 correspond to class 0 (not disaster-related) and values close to 1 correspond to class 1 (disaster-related).\n",
        "\n",
        "Compiling the model: The model is compiled using the binary_crossentropy loss function, which is suitable for binary classification problems, and the Adam optimizer with a learning rate of 0.002. The metrics argument specifies that accuracy will be used as the evaluation metric.\n",
        "\n",
        "Finally, the model.summary() function call outputs a summary of the model architecture and its parameters, which can be useful for understanding the structure of the model."
      ],
      "metadata": {
        "id": "W-Ejx4QYtFOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 32 \n",
        "lstm_out = 32 #output_dim: Dimension of embedding vector\n",
        "model = Sequential() #a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
        "model.add(Embedding(max_features, embed_dim, input_length = X.shape[1])) #using embedding better then one-hot in the cases where mose indices are zero\n",
        "model.add(Dropout(0.2)) #Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.4))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "adam = optimizers.Adam(learning_rate=0.002)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiL6BkEXwKcA",
        "outputId": "972cbf69-7320-471d-f770-59fcd6cb7e7b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 32)            160000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50, 32)            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                8320      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 168,353\n",
            "Trainable params: 168,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs = 10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NanK1ZL3yyHi",
        "outputId": "14fb5e78-43f5-4681-f984-5d2acb48a198"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1333/1333 [==============================] - 81s 58ms/step - loss: 0.3499 - accuracy: 0.8491 - val_loss: 0.2735 - val_accuracy: 0.8894\n",
            "Epoch 2/10\n",
            "1333/1333 [==============================] - 80s 60ms/step - loss: 0.2137 - accuracy: 0.9144 - val_loss: 0.2050 - val_accuracy: 0.9163\n",
            "Epoch 3/10\n",
            "1333/1333 [==============================] - 78s 58ms/step - loss: 0.1634 - accuracy: 0.9337 - val_loss: 0.1855 - val_accuracy: 0.9240\n",
            "Epoch 4/10\n",
            "1333/1333 [==============================] - 78s 59ms/step - loss: 0.1357 - accuracy: 0.9441 - val_loss: 0.1862 - val_accuracy: 0.9288\n",
            "Epoch 5/10\n",
            "1333/1333 [==============================] - 78s 59ms/step - loss: 0.1225 - accuracy: 0.9509 - val_loss: 0.1783 - val_accuracy: 0.9310\n",
            "Epoch 6/10\n",
            "1333/1333 [==============================] - 78s 58ms/step - loss: 0.1083 - accuracy: 0.9550 - val_loss: 0.1845 - val_accuracy: 0.9296\n",
            "Epoch 7/10\n",
            "1333/1333 [==============================] - 84s 63ms/step - loss: 0.0981 - accuracy: 0.9587 - val_loss: 0.1728 - val_accuracy: 0.9376\n",
            "Epoch 8/10\n",
            "1333/1333 [==============================] - 79s 59ms/step - loss: 0.0907 - accuracy: 0.9613 - val_loss: 0.1778 - val_accuracy: 0.9396\n",
            "Epoch 9/10\n",
            "1333/1333 [==============================] - 78s 58ms/step - loss: 0.0844 - accuracy: 0.9647 - val_loss: 0.1765 - val_accuracy: 0.9401\n",
            "Epoch 10/10\n",
            "1333/1333 [==============================] - 78s 58ms/step - loss: 0.0782 - accuracy: 0.9676 - val_loss: 0.1753 - val_accuracy: 0.9416\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f93012ea3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test).round()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYCdTXy-0xJx",
        "outputId": "62659aef-881b-4d4e-e92e-26035f26534e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "334/334 [==============================] - 3s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2-wIOa6GgLt",
        "outputId": "7b24368c-008e-4a17-dcca-b19773e291be"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "M1_CrRIfGl76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = round(metrics.accuracy_score(y_train,model.predict(X_train).round())*100)\n",
        "train_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDOUBIebGnPq",
        "outputId": "ac79bac1-77a1-4282-f6b9-54271d00edca"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1333/1333 [==============================] - 11s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy  is  : ', (metrics.accuracy_score(y_test, y_pred)))\n",
        "print('Recall  is    : ', (metrics.recall_score(y_test, y_pred)))\n",
        "print('Precision  is : ', (metrics.precision_score(y_test, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWcbVXG1Gnxm",
        "outputId": "8b0b260d-f918-4a9d-b64b-f0d992941e46"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  is  :  0.9415517403133502\n",
            "Recall  is    :  0.9158674803836094\n",
            "Precision  is :  0.9466095967560262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission"
      ],
      "metadata": {
        "id": "uHQMSVGqS0Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(test_data_path)"
      ],
      "metadata": {
        "id": "3_P-Q0lQS0jB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "geh6pjZ7trHO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['clean_text'] = test_data['text'].apply(toclean_text)\n",
        "test_data[\"clean_text\"] = test_data[\"clean_text\"].apply(clean_tweet)"
      ],
      "metadata": {
        "id": "GXcsxik53vPa"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(train_data['clean_text'].values)\n",
        "test_token = tokenizer.texts_to_sequences(test_data['clean_text'].values)\n",
        "test_token = pad_sequences(test_token, maxlen =l)"
      ],
      "metadata": {
        "id": "GN6vouuSGTcM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 100\n",
        "lstm_out = 100\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, return_sequences=True,recurrent_dropout=0.4))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(lstm_out,dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "adam = optimizers.Adam(learning_rate=2e-3)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv-L7ZBpGT5X",
        "outputId": "2575dd39-869e-467a-a2ff-0aca7db1514c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 50, 100)           500000    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50, 100)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50, 100)           80400     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 50, 100)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 660,901\n",
            "Trainable params: 660,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "metadata": {
        "id": "UwU6Yks8GbSs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y, epochs = 10,validation_split = 0.2 ,callbacks=[es_callback], batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfzpyjouGc6G",
        "outputId": "c1528508-bc83-4e04-f2ee-302ebeba93ce"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1333/1333 [==============================] - 288s 211ms/step - loss: 0.3208 - accuracy: 0.8666 - val_loss: 0.6867 - val_accuracy: 0.7387\n",
            "Epoch 2/10\n",
            "1333/1333 [==============================] - 287s 215ms/step - loss: 0.1598 - accuracy: 0.9362 - val_loss: 0.8694 - val_accuracy: 0.7318\n",
            "Epoch 3/10\n",
            "1333/1333 [==============================] - 285s 214ms/step - loss: 0.1116 - accuracy: 0.9548 - val_loss: 1.3326 - val_accuracy: 0.7151\n",
            "Epoch 4/10\n",
            "1333/1333 [==============================] - 287s 215ms/step - loss: 0.0884 - accuracy: 0.9637 - val_loss: 1.4224 - val_accuracy: 0.7156\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f92f476b2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model.predict(test_token).round()\n",
        "submission = pd.read_csv(submission_path)\n",
        "submission['target'] = np.round(y_hat).astype('int')\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "submission.describe().style.background_gradient(cmap='coolwarm')"
      ],
      "metadata": {
        "id": "EQGwDgqcGe8O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "85c0c8a7-5a34-4b75-a2ae-15dfaf62df9e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102/102 [==============================] - 3s 29ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f93010497c0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_eb397_row0_col0 {\n",
              "  background-color: #9ebeff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_eb397_row0_col1, #T_eb397_row7_col0 {\n",
              "  background-color: #b40426;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_eb397_row1_col0 {\n",
              "  background-color: #dcdddd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_eb397_row1_col1, #T_eb397_row2_col1, #T_eb397_row3_col0, #T_eb397_row3_col1, #T_eb397_row4_col1, #T_eb397_row5_col1, #T_eb397_row6_col1, #T_eb397_row7_col1 {\n",
              "  background-color: #3b4cc0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_eb397_row2_col0 {\n",
              "  background-color: #9bbcff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_eb397_row4_col0 {\n",
              "  background-color: #8caffe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_eb397_row5_col0 {\n",
              "  background-color: #dedcdb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_eb397_row6_col0 {\n",
              "  background-color: #f4987a;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_eb397_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >id</th>\n",
              "      <th class=\"col_heading level0 col1\" >target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_eb397_level0_row0\" class=\"row_heading level0 row0\" >count</th>\n",
              "      <td id=\"T_eb397_row0_col0\" class=\"data row0 col0\" >3263.000000</td>\n",
              "      <td id=\"T_eb397_row0_col1\" class=\"data row0 col1\" >3263.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_eb397_level0_row1\" class=\"row_heading level0 row1\" >mean</th>\n",
              "      <td id=\"T_eb397_row1_col0\" class=\"data row1 col0\" >5427.152927</td>\n",
              "      <td id=\"T_eb397_row1_col1\" class=\"data row1 col1\" >0.425682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_eb397_level0_row2\" class=\"row_heading level0 row2\" >std</th>\n",
              "      <td id=\"T_eb397_row2_col0\" class=\"data row2 col0\" >3146.427221</td>\n",
              "      <td id=\"T_eb397_row2_col1\" class=\"data row2 col1\" >0.494522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_eb397_level0_row3\" class=\"row_heading level0 row3\" >min</th>\n",
              "      <td id=\"T_eb397_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
              "      <td id=\"T_eb397_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_eb397_level0_row4\" class=\"row_heading level0 row4\" >25%</th>\n",
              "      <td id=\"T_eb397_row4_col0\" class=\"data row4 col0\" >2683.000000</td>\n",
              "      <td id=\"T_eb397_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_eb397_level0_row5\" class=\"row_heading level0 row5\" >50%</th>\n",
              "      <td id=\"T_eb397_row5_col0\" class=\"data row5 col0\" >5500.000000</td>\n",
              "      <td id=\"T_eb397_row5_col1\" class=\"data row5 col1\" >0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_eb397_level0_row6\" class=\"row_heading level0 row6\" >75%</th>\n",
              "      <td id=\"T_eb397_row6_col0\" class=\"data row6 col0\" >8176.000000</td>\n",
              "      <td id=\"T_eb397_row6_col1\" class=\"data row6 col1\" >1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_eb397_level0_row7\" class=\"row_heading level0 row7\" >max</th>\n",
              "      <td id=\"T_eb397_row7_col0\" class=\"data row7 col0\" >10875.000000</td>\n",
              "      <td id=\"T_eb397_row7_col1\" class=\"data row7 col1\" >1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.target.value_counts().plot.bar();"
      ],
      "metadata": {
        "id": "5BUY0nKUGhKh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "9563b6b5-8c83-472f-8522-0135c6e3bc85"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}